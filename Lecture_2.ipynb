{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Lecture 2\n",
    "**7 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh ([S.vanCranenburgh@tudelft.nl]())\n",
    "- Francisco Garrido-Valenzuela ([F.O.GarridoValenzuela@tudelft.nl]())\n",
    "\n",
    "**This notebook will not be graded. You do not have to submit the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "### Using Colab\n",
    "\n",
    "Students using **Colab**, are ready to work! :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Exercise 3: The effect of the number of nodes and the learning rate on the model performance and training of ANNs\n",
    "\n",
    "**Objectives:** \n",
    "* Understand the effects of number of nodes on the model performance\n",
    "* Understand the the effect of the learning rate on training time and model convergence\n",
    "* Apply Tensor Flow 2 to create and train more advanced ANN typologies\n",
    "\n",
    "### i. import Python packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Using tensorflow \",tf.__version__)\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML packaged and modules\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Load the data and create a dataframe \n",
    "Note that we use the samedata set as in Lecture 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data\n",
    "df = pd.read_csv('week6/datasets/dcm/smartphone_choicedata2021.csv', sep='\\t')\n",
    "\n",
    "# Define the features\n",
    "X = df[['COST_1','SIZE_1','STORAGE_1','CAM_1','COST_2','SIZE_2','STORAGE_2','CAM_2','COST_3','SIZE_3','STORAGE_3','CAM_3','GENDER','INC']]\n",
    "\n",
    "# Define the output target\n",
    "Y = df['CHOICE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Split the data in a training set and a test set and rescale the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in a training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33)\n",
    "\n",
    "# Define scaler \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "\n",
    "# Apply scaler to both the training and test set\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Investigate the effect of the number of nodes on the model performance\n",
    "To do so, we use the same ANN as in Exercise 2. But, we train this ANN using a different number of nodes in the hidden layers: [1,2,3,5,7,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model for using it in the for loop\n",
    "def new_ann_sk(num_nodes = 5, epoch = 400):\n",
    "\n",
    "    # Buid the ANN\n",
    "    layers = (num_nodes,num_nodes) # Here we use a network with two hidden layers, with *num_nodes* each \n",
    "\n",
    "    # Create the ANNs (MultiLayerPerceptron aka MLP)\n",
    "    mlp = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = layers, max_iter = 1000) \n",
    "\n",
    "    # Train the ANN. Note that sklearn does not permit anything else than batch gradient descent\n",
    "    mlp.fit(X_train, Y_train)\n",
    "\n",
    "    # Use the trained ANN to make predictions for the test data\n",
    "    probs_ANN_X_test = mlp.predict_proba(X_test)\n",
    "\n",
    "    # Compute the prediction performance, based on the cross-entropy (aka log_loss). A lower cross-entropy signals a better model.\n",
    "    cross_entropy_ANN = log_loss(Y_test, probs_ANN_X_test)\n",
    "    #print(f'The cross-entropy on the test data of the ANN with {num_nodes} is {cross_entropy_ANN}')\n",
    "    return cross_entropy_ANN\n",
    "\n",
    "\n",
    "# Train the model using a different number of nodes and collec the cross-entropy for each typology\n",
    "nodes_range = [1,2,3,5,7,10]\n",
    "cross_val = []\n",
    "for nneurons in nodes_range:\n",
    "    cross_val.append(new_ann_sk(num_nodes = nneurons, epoch = 400))\n",
    "\n",
    "# Plot cross entropy as a function the number of nodes in the (two) hidden layers\n",
    "plt.subplot(111)\n",
    "plt.plot(nodes_range,cross_val, color = 'blue', label = 'test')\n",
    "plt.xlabel('Number of nodes at the hidden layers')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.ylim(0.4, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1. Regarding the effect of the nodes:\n",
    "- #### (a) What is the 'optimal number of nodes' for these data set?\n",
    "- #### (b) Why does adding more nodes lead to a better model performance (up until some point)?\n",
    "- #### (c) Why does the model performance not further improve when adding more nodes after say 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Rebuild the ANN in TensorFlow\n",
    "Next, we rebuild the ANN of SKLearn in TensorFlow (TF). TF allows for building more advanced networks and for more custom tweaking and tuning. We need TF to be able to build the Hybrid ANNs in exercise 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Convert output labels to categoricals\n",
    "TF requires the output labels the be categorical for classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_c = to_categorical(Y_train-1, num_classes = 3)\n",
    "Y_test_c = to_categorical(Y_test-1, num_classes = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Building the ANN structure\n",
    "\n",
    "In TF there are various ways to build a network. Here we use Keras **Functional API**. The Keras functional API is a way to create graph neural networks that are more flexible than using a **Sequential API**. The Functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "- [Functional API documentation](https://www.tensorflow.org/guide/keras/functional)\n",
    "- [Sequential API documentation](https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "We build the layers one by one and then create the model by pulling these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (InputLayer)        [(None, 14)]              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 5)                 75        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 20:51:50.178446: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create the input layer\n",
    "X = Input((X_train.shape[1]), name ='features')\n",
    "\n",
    "# Create the hidden layers\n",
    "num_nodes = 5 # Number of nodes per hidden layer\n",
    "layer1 = Dense(units = num_nodes, name = \"layer1\", use_bias = True)(X)           \n",
    "layer2 = Dense(units = num_nodes, name = \"layer2\", use_bias = True)(layer1)\n",
    "\n",
    "# Create the output layer \n",
    "Y = Dense(units = Y_train_c.shape[1], activation='softmax', name = \"output\")(layer2) \n",
    "\n",
    "# Create the model by indicating the input and outputs in the graph of layers\n",
    "model = Model(inputs = X, outputs = Y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 20:51:50.269863: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 1.3866 - accuracy: 0.3670 - val_loss: 1.2791 - val_accuracy: 0.3867\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2803 - accuracy: 0.3882 - val_loss: 1.1842 - val_accuracy: 0.3870\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1863 - accuracy: 0.3872 - val_loss: 1.1029 - val_accuracy: 0.4148\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1058 - accuracy: 0.4106 - val_loss: 1.0359 - val_accuracy: 0.4718\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0392 - accuracy: 0.4648 - val_loss: 0.9828 - val_accuracy: 0.5203\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9864 - accuracy: 0.5084 - val_loss: 0.9426 - val_accuracy: 0.5552\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9460 - accuracy: 0.5449 - val_loss: 0.9130 - val_accuracy: 0.5739\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9159 - accuracy: 0.5643 - val_loss: 0.8912 - val_accuracy: 0.5773\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8933 - accuracy: 0.5654 - val_loss: 0.8746 - val_accuracy: 0.5773\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8757 - accuracy: 0.5654 - val_loss: 0.8610 - val_accuracy: 0.6024\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8609 - accuracy: 0.5894 - val_loss: 0.8490 - val_accuracy: 0.6385\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8476 - accuracy: 0.6337 - val_loss: 0.8378 - val_accuracy: 0.6448\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8351 - accuracy: 0.6473 - val_loss: 0.8268 - val_accuracy: 0.6670\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8230 - accuracy: 0.6688 - val_loss: 0.8159 - val_accuracy: 0.7027\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8110 - accuracy: 0.7072 - val_loss: 0.8049 - val_accuracy: 0.7191\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7990 - accuracy: 0.7221 - val_loss: 0.7938 - val_accuracy: 0.7448\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7872 - accuracy: 0.7472 - val_loss: 0.7828 - val_accuracy: 0.7406\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7756 - accuracy: 0.7457 - val_loss: 0.7718 - val_accuracy: 0.7412\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7642 - accuracy: 0.7473 - val_loss: 0.7609 - val_accuracy: 0.7409\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7530 - accuracy: 0.7460 - val_loss: 0.7502 - val_accuracy: 0.7409\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7422 - accuracy: 0.7460 - val_loss: 0.7399 - val_accuracy: 0.7409\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7319 - accuracy: 0.7460 - val_loss: 0.7299 - val_accuracy: 0.7409\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7219 - accuracy: 0.7460 - val_loss: 0.7204 - val_accuracy: 0.7409\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7125 - accuracy: 0.7460 - val_loss: 0.7113 - val_accuracy: 0.7409\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7036 - accuracy: 0.7460 - val_loss: 0.7027 - val_accuracy: 0.7409\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6951 - accuracy: 0.7460 - val_loss: 0.6947 - val_accuracy: 0.7409\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6872 - accuracy: 0.7460 - val_loss: 0.6873 - val_accuracy: 0.7509\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6797 - accuracy: 0.7564 - val_loss: 0.6804 - val_accuracy: 0.7509\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6727 - accuracy: 0.7564 - val_loss: 0.6740 - val_accuracy: 0.7509\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6662 - accuracy: 0.7564 - val_loss: 0.6682 - val_accuracy: 0.7509\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6601 - accuracy: 0.7564 - val_loss: 0.6629 - val_accuracy: 0.7509\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6544 - accuracy: 0.7564 - val_loss: 0.6581 - val_accuracy: 0.7509\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6491 - accuracy: 0.7564 - val_loss: 0.6539 - val_accuracy: 0.7509\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6443 - accuracy: 0.7564 - val_loss: 0.6501 - val_accuracy: 0.7509\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6399 - accuracy: 0.7564 - val_loss: 0.6467 - val_accuracy: 0.7509\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6359 - accuracy: 0.7564 - val_loss: 0.6436 - val_accuracy: 0.7509\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6322 - accuracy: 0.7564 - val_loss: 0.6408 - val_accuracy: 0.7509\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6288 - accuracy: 0.7564 - val_loss: 0.6382 - val_accuracy: 0.7509\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6256 - accuracy: 0.7564 - val_loss: 0.6356 - val_accuracy: 0.7509\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6226 - accuracy: 0.7564 - val_loss: 0.6331 - val_accuracy: 0.7509\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6198 - accuracy: 0.7564 - val_loss: 0.6307 - val_accuracy: 0.7509\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6171 - accuracy: 0.7564 - val_loss: 0.6284 - val_accuracy: 0.7509\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6146 - accuracy: 0.7564 - val_loss: 0.6261 - val_accuracy: 0.7509\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6123 - accuracy: 0.7564 - val_loss: 0.6239 - val_accuracy: 0.7509\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6102 - accuracy: 0.7564 - val_loss: 0.6219 - val_accuracy: 0.7509\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6082 - accuracy: 0.7564 - val_loss: 0.6200 - val_accuracy: 0.7509\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6065 - accuracy: 0.7564 - val_loss: 0.6183 - val_accuracy: 0.7509\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6049 - accuracy: 0.7564 - val_loss: 0.6167 - val_accuracy: 0.7409\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6035 - accuracy: 0.7460 - val_loss: 0.6153 - val_accuracy: 0.7409\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6023 - accuracy: 0.7460 - val_loss: 0.6141 - val_accuracy: 0.7409\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6011 - accuracy: 0.7460 - val_loss: 0.6130 - val_accuracy: 0.7409\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6001 - accuracy: 0.7460 - val_loss: 0.6121 - val_accuracy: 0.7409\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5992 - accuracy: 0.7460 - val_loss: 0.6114 - val_accuracy: 0.7409\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5985 - accuracy: 0.7460 - val_loss: 0.6108 - val_accuracy: 0.7409\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5979 - accuracy: 0.7460 - val_loss: 0.6104 - val_accuracy: 0.7409\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5975 - accuracy: 0.7460 - val_loss: 0.6100 - val_accuracy: 0.7409\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5971 - accuracy: 0.7460 - val_loss: 0.6096 - val_accuracy: 0.7409\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5967 - accuracy: 0.7460 - val_loss: 0.6092 - val_accuracy: 0.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5964 - accuracy: 0.7460 - val_loss: 0.6088 - val_accuracy: 0.7409\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5961 - accuracy: 0.7460 - val_loss: 0.6083 - val_accuracy: 0.7409\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5958 - accuracy: 0.7460 - val_loss: 0.6077 - val_accuracy: 0.7409\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5954 - accuracy: 0.7460 - val_loss: 0.6071 - val_accuracy: 0.7509\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5950 - accuracy: 0.7564 - val_loss: 0.6064 - val_accuracy: 0.7509\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5947 - accuracy: 0.7564 - val_loss: 0.6058 - val_accuracy: 0.7509\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5943 - accuracy: 0.7564 - val_loss: 0.6053 - val_accuracy: 0.7509\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5940 - accuracy: 0.7564 - val_loss: 0.6048 - val_accuracy: 0.7509\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5938 - accuracy: 0.7564 - val_loss: 0.6044 - val_accuracy: 0.7509\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5936 - accuracy: 0.7564 - val_loss: 0.6041 - val_accuracy: 0.7509\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5934 - accuracy: 0.7564 - val_loss: 0.6038 - val_accuracy: 0.7509\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5932 - accuracy: 0.7564 - val_loss: 0.6036 - val_accuracy: 0.7509\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5931 - accuracy: 0.7564 - val_loss: 0.6034 - val_accuracy: 0.7509\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5929 - accuracy: 0.7564 - val_loss: 0.6032 - val_accuracy: 0.7509\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5928 - accuracy: 0.7564 - val_loss: 0.6030 - val_accuracy: 0.7509\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5926 - accuracy: 0.7564 - val_loss: 0.6028 - val_accuracy: 0.7509\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5924 - accuracy: 0.7564 - val_loss: 0.6027 - val_accuracy: 0.7509\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5922 - accuracy: 0.7564 - val_loss: 0.6025 - val_accuracy: 0.7509\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5920 - accuracy: 0.7564 - val_loss: 0.6022 - val_accuracy: 0.7509\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5918 - accuracy: 0.7564 - val_loss: 0.6020 - val_accuracy: 0.7509\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5916 - accuracy: 0.7564 - val_loss: 0.6018 - val_accuracy: 0.7509\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5914 - accuracy: 0.7564 - val_loss: 0.6017 - val_accuracy: 0.7509\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5912 - accuracy: 0.7564 - val_loss: 0.6015 - val_accuracy: 0.7509\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5911 - accuracy: 0.7564 - val_loss: 0.6013 - val_accuracy: 0.7509\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5909 - accuracy: 0.7564 - val_loss: 0.6011 - val_accuracy: 0.7509\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5908 - accuracy: 0.7564 - val_loss: 0.6010 - val_accuracy: 0.7509\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5907 - accuracy: 0.7564 - val_loss: 0.6008 - val_accuracy: 0.7509\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5905 - accuracy: 0.7564 - val_loss: 0.6007 - val_accuracy: 0.7509\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5904 - accuracy: 0.7564 - val_loss: 0.6005 - val_accuracy: 0.7509\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5903 - accuracy: 0.7564 - val_loss: 0.6003 - val_accuracy: 0.7509\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5902 - accuracy: 0.7564 - val_loss: 0.6002 - val_accuracy: 0.7509\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5901 - accuracy: 0.7564 - val_loss: 0.6000 - val_accuracy: 0.7509\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5900 - accuracy: 0.7564 - val_loss: 0.5999 - val_accuracy: 0.7509\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5899 - accuracy: 0.7564 - val_loss: 0.5997 - val_accuracy: 0.7509\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5898 - accuracy: 0.7564 - val_loss: 0.5996 - val_accuracy: 0.7509\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5897 - accuracy: 0.7564 - val_loss: 0.5994 - val_accuracy: 0.7509\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5896 - accuracy: 0.7564 - val_loss: 0.5993 - val_accuracy: 0.7509\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5895 - accuracy: 0.7564 - val_loss: 0.5991 - val_accuracy: 0.7509\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5894 - accuracy: 0.7564 - val_loss: 0.5990 - val_accuracy: 0.7509\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5893 - accuracy: 0.7564 - val_loss: 0.5989 - val_accuracy: 0.7509\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5893 - accuracy: 0.7564 - val_loss: 0.5988 - val_accuracy: 0.7509\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5892 - accuracy: 0.7564 - val_loss: 0.5987 - val_accuracy: 0.7509\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5891 - accuracy: 0.7564 - val_loss: 0.5986 - val_accuracy: 0.7509\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5891 - accuracy: 0.7564 - val_loss: 0.5986 - val_accuracy: 0.7509\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5890 - accuracy: 0.7564 - val_loss: 0.5985 - val_accuracy: 0.7509\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5889 - accuracy: 0.7564 - val_loss: 0.5984 - val_accuracy: 0.7509\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5889 - accuracy: 0.7564 - val_loss: 0.5983 - val_accuracy: 0.7509\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5888 - accuracy: 0.7564 - val_loss: 0.5982 - val_accuracy: 0.7509\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5888 - accuracy: 0.7564 - val_loss: 0.5981 - val_accuracy: 0.7509\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5887 - accuracy: 0.7564 - val_loss: 0.5980 - val_accuracy: 0.7509\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5887 - accuracy: 0.7564 - val_loss: 0.5979 - val_accuracy: 0.7509\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5886 - accuracy: 0.7564 - val_loss: 0.5978 - val_accuracy: 0.7509\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5886 - accuracy: 0.7564 - val_loss: 0.5977 - val_accuracy: 0.7509\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5885 - accuracy: 0.7564 - val_loss: 0.5976 - val_accuracy: 0.7509\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5885 - accuracy: 0.7564 - val_loss: 0.5975 - val_accuracy: 0.7509\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5884 - accuracy: 0.7564 - val_loss: 0.5974 - val_accuracy: 0.7509\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5884 - accuracy: 0.7564 - val_loss: 0.5974 - val_accuracy: 0.7509\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5883 - accuracy: 0.7564 - val_loss: 0.5973 - val_accuracy: 0.7509\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5883 - accuracy: 0.7564 - val_loss: 0.5973 - val_accuracy: 0.7509\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5882 - accuracy: 0.7564 - val_loss: 0.5972 - val_accuracy: 0.7509\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5882 - accuracy: 0.7564 - val_loss: 0.5972 - val_accuracy: 0.7509\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5882 - accuracy: 0.7564 - val_loss: 0.5972 - val_accuracy: 0.7509\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5881 - accuracy: 0.7564 - val_loss: 0.5971 - val_accuracy: 0.7509\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5881 - accuracy: 0.7564 - val_loss: 0.5971 - val_accuracy: 0.7509\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5880 - accuracy: 0.7564 - val_loss: 0.5970 - val_accuracy: 0.7509\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5880 - accuracy: 0.7564 - val_loss: 0.5970 - val_accuracy: 0.7509\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5880 - accuracy: 0.7564 - val_loss: 0.5969 - val_accuracy: 0.7509\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5879 - accuracy: 0.7564 - val_loss: 0.5969 - val_accuracy: 0.7509\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5879 - accuracy: 0.7564 - val_loss: 0.5968 - val_accuracy: 0.7509\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5879 - accuracy: 0.7564 - val_loss: 0.5967 - val_accuracy: 0.7509\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5878 - accuracy: 0.7564 - val_loss: 0.5967 - val_accuracy: 0.7509\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5878 - accuracy: 0.7564 - val_loss: 0.5966 - val_accuracy: 0.7509\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5878 - accuracy: 0.7564 - val_loss: 0.5966 - val_accuracy: 0.7509\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5877 - accuracy: 0.7564 - val_loss: 0.5965 - val_accuracy: 0.7509\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5877 - accuracy: 0.7564 - val_loss: 0.5965 - val_accuracy: 0.7509\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5877 - accuracy: 0.7564 - val_loss: 0.5964 - val_accuracy: 0.7509\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5877 - accuracy: 0.7564 - val_loss: 0.5964 - val_accuracy: 0.7509\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5876 - accuracy: 0.7564 - val_loss: 0.5964 - val_accuracy: 0.7509\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5876 - accuracy: 0.7564 - val_loss: 0.5963 - val_accuracy: 0.7509\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5876 - accuracy: 0.7564 - val_loss: 0.5963 - val_accuracy: 0.7509\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5875 - accuracy: 0.7564 - val_loss: 0.5963 - val_accuracy: 0.7509\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7564 - val_loss: 0.5962 - val_accuracy: 0.7509\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7564 - val_loss: 0.5962 - val_accuracy: 0.7509\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5875 - accuracy: 0.7564 - val_loss: 0.5962 - val_accuracy: 0.7509\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7564 - val_loss: 0.5962 - val_accuracy: 0.7509\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5874 - accuracy: 0.7564 - val_loss: 0.5961 - val_accuracy: 0.7509\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5874 - accuracy: 0.7564 - val_loss: 0.5961 - val_accuracy: 0.7509\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5874 - accuracy: 0.7564 - val_loss: 0.5961 - val_accuracy: 0.7509\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5874 - accuracy: 0.7564 - val_loss: 0.5960 - val_accuracy: 0.7509\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5873 - accuracy: 0.7564 - val_loss: 0.5960 - val_accuracy: 0.7509\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5873 - accuracy: 0.7564 - val_loss: 0.5960 - val_accuracy: 0.7509\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5873 - accuracy: 0.7564 - val_loss: 0.5960 - val_accuracy: 0.7509\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5873 - accuracy: 0.7564 - val_loss: 0.5959 - val_accuracy: 0.7509\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5873 - accuracy: 0.7564 - val_loss: 0.5959 - val_accuracy: 0.7509\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5872 - accuracy: 0.7564 - val_loss: 0.5959 - val_accuracy: 0.7509\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5872 - accuracy: 0.7564 - val_loss: 0.5958 - val_accuracy: 0.7509\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5872 - accuracy: 0.7564 - val_loss: 0.5958 - val_accuracy: 0.7509\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5872 - accuracy: 0.7564 - val_loss: 0.5958 - val_accuracy: 0.7509\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5872 - accuracy: 0.7564 - val_loss: 0.5958 - val_accuracy: 0.7509\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5957 - val_accuracy: 0.7509\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5957 - val_accuracy: 0.7509\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5957 - val_accuracy: 0.7509\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5957 - val_accuracy: 0.7509\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5957 - val_accuracy: 0.7509\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5956 - val_accuracy: 0.7509\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5871 - accuracy: 0.7564 - val_loss: 0.5956 - val_accuracy: 0.7509\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5956 - val_accuracy: 0.7509\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5956 - val_accuracy: 0.7509\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5956 - val_accuracy: 0.7509\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5870 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5955 - val_accuracy: 0.7509\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5869 - accuracy: 0.7564 - val_loss: 0.5954 - val_accuracy: 0.7509\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5953 - val_accuracy: 0.7509\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5868 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5952 - val_accuracy: 0.7509\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5951 - val_accuracy: 0.7509\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5950 - val_accuracy: 0.7509\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5866 - accuracy: 0.7564 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5948 - val_accuracy: 0.7509\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5947 - val_accuracy: 0.7509\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5865 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5864 - accuracy: 0.7564 - val_loss: 0.5946 - val_accuracy: 0.7509\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.586\n"
     ]
    }
   ],
   "source": [
    "# Compile the model, passing the traning configuration\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "\n",
    "# Early stopping stops the training once the performance on the test set no longer improves\n",
    "early_stopping = EarlyStopping(patience = 3, monitor = 'val_loss')\n",
    "\n",
    "# Train the model, while keeping track of the performance at each epoch\n",
    "history = model.fit(X_train,Y_train_c, batch_size=len(X_train), epochs = 1000, verbose = 1, validation_data = (X_test, Y_test_c), callbacks = [early_stopping])\n",
    "\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.4,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2. Probably the model performance varies between the TF and SKlearn implementation of the ANN. Why do we not find the exact same results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3. Try different values for the \"learning rate\" to investigate its effect on the training time and model convergence/performance. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'>\n",
    "\n",
    "**ANSWER**\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## **Exercise 4: Build the Hybrid RUM-MNL-ANN model**\n",
    "\n",
    "**Objective:**  See how by combining ANNs and DCMs the best of both worlds, in terms of model peformance and interpretability can be attained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Declare properties of the data set and training settings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NALT = 3           # Number of alterantives in the data set.\n",
    "no_X_MNL = 2       # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the WtP for extra storage space --> Cost & Storage\n",
    "no_X_ANN = 8       # Number of features without behavioural interest (-->ANN model part). In this example we are not behaviourall interested in Camera, Size, and the socio demographic variables\n",
    "num_nodes = 5      # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "nEpoch = 500       # Number epochs for training (max). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Create the layers of the MNL part of the hybrid model\n",
    "\n",
    "Using the structure of TF Functional API. The MNL part is made as follow:\n",
    "\n",
    "<img src=\"https://github.com/cs4305tu/week6/blob/main/MNLpart.png?raw=true\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR MNL PART\n",
    "X_MNL = Input((no_X_MNL, NALT,1), name = 'Features2MNL')\n",
    "\n",
    "# COMPUTE UTILITY FOR MNL\n",
    "V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (1,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Create the layers of the ANN part of the hybrid model\n",
    "\n",
    "Using the structure of TF Functional API. The ANN part is made as follow:\n",
    "\n",
    "<img src=\"https://github.com/cs4305tu/week6/blob/main/ANNpart.png?raw=true\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR ANN PART\n",
    "X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "# CREATE HIDDEN LAYER(S) OF ANN\n",
    "layer1_ANN = Dense(units = num_nodes, name = \"ANN_layer1\", use_bias = True)(X_ANN) \n",
    "layer2_ANN = Dense(units = num_nodes, name = \"ANN_layer2\", use_bias = True)(layer1_ANN)\n",
    "\n",
    "# COMPUTE UTILITY FOR ANN \n",
    "V_ANN = Dense(units = NALT, name = \"V_ANN\")(layer2_ANN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Combine the MNL and ANN parts and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE TENSORS TO [1 X NALT]\n",
    "V_MNL = Reshape([NALT], name = 'Flatten_Dim_MNL')(V_MNL)\n",
    "V_ANN = Reshape([NALT], name = 'Flatten_Dim_ANN')(V_ANN) \n",
    "\n",
    "# SUM THE UTILITIES OF BOTH MODEL PARTS\n",
    "V_MNL_ANN = Add(name = \"Combining_Vs\")([V_MNL,V_ANN])\n",
    "\n",
    "# CREATE LOGIT (AKA SOFTMAX ) OUTPUT LAYER\n",
    "logits = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "# BUILD THE MODEL\n",
    "model = Model(inputs = [X_MNL, X_ANN], outputs = logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Define the input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the output class\n",
    "X = df[['COST_1','SIZE_1','STORAGE_1','CAM_1','COST_2','SIZE_2','STORAGE_2','CAM_2','COST_3','SIZE_3','STORAGE_3','CAM_3','GENDER','INC']]\n",
    "\n",
    "# Define the output target\n",
    "Y = df['CHOICE']\n",
    "Y_cat = to_categorical(Y-1, num_classes = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Create input variables for both parts of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (10000, 2, 3, 1)\n",
      "Shape of x_ann (10000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create x input for MNL layer, and rescale\n",
    "scale = 100 # We cannot just use the sklearn scaler here, as it is import for the interpretation later how the input data are scaled. \n",
    "\n",
    "x_mnl = np.array([[np.divide(X['COST_1'], scale), np.divide(X['STORAGE_1'], scale)],\n",
    "                  [np.divide(X['COST_2'], scale), np.divide(X['STORAGE_2'], scale)],\n",
    "                  [np.divide(X['COST_3'], scale), np.divide(X['STORAGE_3'], scale)]])\n",
    "x_mnl = np.swapaxes(x_mnl, 0, 2)\n",
    "x_mnl = np.expand_dims(x_mnl, 3)\n",
    "print('Shape of x_mnl', x_mnl.shape)\n",
    "\n",
    "# Create x input for ANN layer\n",
    "x_ann = np.array([[X['SIZE_1'], X['CAM_1'], X['SIZE_2'], X['CAM_2'], X['SIZE_3'], X['CAM_3'], X['GENDER'], X['INC']]])\n",
    "x_ann = np.squeeze(np.swapaxes(x_ann, 0, 2))\n",
    "\n",
    "# Rescale input for the ANN part\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_ann)  \n",
    "x_ann = scaler.transform(x_ann)  \n",
    "print('Shape of x_ann',x_ann.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii. Split the data in a training set and a test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obervations in the data set =  10000\n",
      "Number of obervations in the training set   =  6500\n",
      "Number of obervations in the test set       =  3500\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test part\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('Total number of obervations in the data set = ', len(x_mnl))\n",
    "print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of obervations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viii. Compile the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            45          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 95\n",
      "Trainable params: 95\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ix. Train the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 2.2249 - accuracy: 0.1691 - val_loss: 2.1172 - val_accuracy: 0.1874\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1020 - accuracy: 0.1877 - val_loss: 2.0049 - val_accuracy: 0.1874\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.9897 - accuracy: 0.1877 - val_loss: 1.9021 - val_accuracy: 0.1874\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8871 - accuracy: 0.1877 - val_loss: 1.8080 - val_accuracy: 0.1874\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7935 - accuracy: 0.1877 - val_loss: 1.7221 - val_accuracy: 0.1874\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7083 - accuracy: 0.1877 - val_loss: 1.6438 - val_accuracy: 0.1760\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6310 - accuracy: 0.1786 - val_loss: 1.5731 - val_accuracy: 0.1774\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5612 - accuracy: 0.1820 - val_loss: 1.5097 - val_accuracy: 0.2146\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4990 - accuracy: 0.2211 - val_loss: 1.4536 - val_accuracy: 0.2431\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4442 - accuracy: 0.2505 - val_loss: 1.4047 - val_accuracy: 0.2903\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3966 - accuracy: 0.2923 - val_loss: 1.3625 - val_accuracy: 0.3494\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3559 - accuracy: 0.3611 - val_loss: 1.3266 - val_accuracy: 0.3811\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3213 - accuracy: 0.3917 - val_loss: 1.2961 - val_accuracy: 0.4051\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2921 - accuracy: 0.4108 - val_loss: 1.2701 - val_accuracy: 0.4389\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2673 - accuracy: 0.4440 - val_loss: 1.2478 - val_accuracy: 0.4289\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2460 - accuracy: 0.4371 - val_loss: 1.2282 - val_accuracy: 0.4689\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2273 - accuracy: 0.4695 - val_loss: 1.2107 - val_accuracy: 0.4534\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2104 - accuracy: 0.4511 - val_loss: 1.1946 - val_accuracy: 0.4386\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1947 - accuracy: 0.4291 - val_loss: 1.1795 - val_accuracy: 0.4466\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1797 - accuracy: 0.4375 - val_loss: 1.1650 - val_accuracy: 0.4677\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1652 - accuracy: 0.4583 - val_loss: 1.1511 - val_accuracy: 0.4731\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1510 - accuracy: 0.4629 - val_loss: 1.1375 - val_accuracy: 0.4731\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1371 - accuracy: 0.4629 - val_loss: 1.1244 - val_accuracy: 0.4731\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1235 - accuracy: 0.4629 - val_loss: 1.1117 - val_accuracy: 0.4940\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1102 - accuracy: 0.4829 - val_loss: 1.0996 - val_accuracy: 0.4909\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0974 - accuracy: 0.4775 - val_loss: 1.0881 - val_accuracy: 0.4894\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0852 - accuracy: 0.4775 - val_loss: 1.0772 - val_accuracy: 0.4780\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0736 - accuracy: 0.4685 - val_loss: 1.0669 - val_accuracy: 0.4623\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0626 - accuracy: 0.4589 - val_loss: 1.0571 - val_accuracy: 0.4809\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0522 - accuracy: 0.4772 - val_loss: 1.0479 - val_accuracy: 0.4809\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0423 - accuracy: 0.4772 - val_loss: 1.0390 - val_accuracy: 0.4846\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0330 - accuracy: 0.4828 - val_loss: 1.0305 - val_accuracy: 0.5289\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0241 - accuracy: 0.5286 - val_loss: 1.0224 - val_accuracy: 0.5289\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0155 - accuracy: 0.5286 - val_loss: 1.0146 - val_accuracy: 0.5289\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0074 - accuracy: 0.5286 - val_loss: 1.0071 - val_accuracy: 0.5289\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9996 - accuracy: 0.5286 - val_loss: 0.9999 - val_accuracy: 0.5417\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9922 - accuracy: 0.5423 - val_loss: 0.9930 - val_accuracy: 0.5417\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9851 - accuracy: 0.5423 - val_loss: 0.9864 - val_accuracy: 0.5606\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9782 - accuracy: 0.5603 - val_loss: 0.9799 - val_accuracy: 0.5606\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9715 - accuracy: 0.5603 - val_loss: 0.9735 - val_accuracy: 0.5769\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9650 - accuracy: 0.5752 - val_loss: 0.9673 - val_accuracy: 0.5769\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9585 - accuracy: 0.5752 - val_loss: 0.9611 - val_accuracy: 0.5769\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9521 - accuracy: 0.5752 - val_loss: 0.9549 - val_accuracy: 0.5686\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9457 - accuracy: 0.5663 - val_loss: 0.9487 - val_accuracy: 0.5686\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9393 - accuracy: 0.5663 - val_loss: 0.9425 - val_accuracy: 0.5686\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9328 - accuracy: 0.5663 - val_loss: 0.9363 - val_accuracy: 0.5686\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9264 - accuracy: 0.5663 - val_loss: 0.9302 - val_accuracy: 0.5686\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9200 - accuracy: 0.5663 - val_loss: 0.9240 - val_accuracy: 0.5686\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9136 - accuracy: 0.5663 - val_loss: 0.9179 - val_accuracy: 0.5686\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9072 - accuracy: 0.5663 - val_loss: 0.9118 - val_accuracy: 0.5686\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9009 - accuracy: 0.5663 - val_loss: 0.9057 - val_accuracy: 0.5686\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8947 - accuracy: 0.5663 - val_loss: 0.8997 - val_accuracy: 0.5834\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8885 - accuracy: 0.5832 - val_loss: 0.8937 - val_accuracy: 0.5834\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8824 - accuracy: 0.5832 - val_loss: 0.8879 - val_accuracy: 0.5834\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8764 - accuracy: 0.5832 - val_loss: 0.8822 - val_accuracy: 0.5834\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8706 - accuracy: 0.5832 - val_loss: 0.8765 - val_accuracy: 0.5834\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8649 - accuracy: 0.5832 - val_loss: 0.8711 - val_accuracy: 0.5834\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8594 - accuracy: 0.5832 - val_loss: 0.8657 - val_accuracy: 0.5834\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8540 - accuracy: 0.5832 - val_loss: 0.8606 - val_accuracy: 0.5834\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8488 - accuracy: 0.5832 - val_loss: 0.8555 - val_accuracy: 0.5920\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8437 - accuracy: 0.5885 - val_loss: 0.8507 - val_accuracy: 0.5874\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8388 - accuracy: 0.5837 - val_loss: 0.8459 - val_accuracy: 0.5889\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8340 - accuracy: 0.5848 - val_loss: 0.8414 - val_accuracy: 0.6049\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8293 - accuracy: 0.6058 - val_loss: 0.8370 - val_accuracy: 0.6203\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8248 - accuracy: 0.6163 - val_loss: 0.8327 - val_accuracy: 0.6423\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8204 - accuracy: 0.6343 - val_loss: 0.8286 - val_accuracy: 0.6391\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8161 - accuracy: 0.6323 - val_loss: 0.8246 - val_accuracy: 0.6391\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8119 - accuracy: 0.6323 - val_loss: 0.8207 - val_accuracy: 0.6391\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8078 - accuracy: 0.6323 - val_loss: 0.8169 - val_accuracy: 0.6391\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8038 - accuracy: 0.6323 - val_loss: 0.8133 - val_accuracy: 0.6414\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8000 - accuracy: 0.6372 - val_loss: 0.8098 - val_accuracy: 0.6394\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7962 - accuracy: 0.6368 - val_loss: 0.8064 - val_accuracy: 0.6394\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7926 - accuracy: 0.6368 - val_loss: 0.8032 - val_accuracy: 0.6394\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7891 - accuracy: 0.6368 - val_loss: 0.8001 - val_accuracy: 0.6394\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7857 - accuracy: 0.6368 - val_loss: 0.7971 - val_accuracy: 0.6394\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7825 - accuracy: 0.6368 - val_loss: 0.7942 - val_accuracy: 0.6394\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7794 - accuracy: 0.6368 - val_loss: 0.7914 - val_accuracy: 0.6549\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7764 - accuracy: 0.6552 - val_loss: 0.7888 - val_accuracy: 0.6549\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7735 - accuracy: 0.6552 - val_loss: 0.7862 - val_accuracy: 0.6549\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7708 - accuracy: 0.6552 - val_loss: 0.7837 - val_accuracy: 0.6549\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7682 - accuracy: 0.6552 - val_loss: 0.7814 - val_accuracy: 0.6654\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7657 - accuracy: 0.6646 - val_loss: 0.7791 - val_accuracy: 0.6654\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7633 - accuracy: 0.6646 - val_loss: 0.7769 - val_accuracy: 0.6654\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7609 - accuracy: 0.6646 - val_loss: 0.7748 - val_accuracy: 0.6654\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7587 - accuracy: 0.6646 - val_loss: 0.7729 - val_accuracy: 0.6654\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7565 - accuracy: 0.6646 - val_loss: 0.7710 - val_accuracy: 0.6654\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7544 - accuracy: 0.6646 - val_loss: 0.7692 - val_accuracy: 0.6654\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7524 - accuracy: 0.6646 - val_loss: 0.7674 - val_accuracy: 0.6843\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7505 - accuracy: 0.6845 - val_loss: 0.7657 - val_accuracy: 0.6843\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7486 - accuracy: 0.6845 - val_loss: 0.7640 - val_accuracy: 0.6843\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7468 - accuracy: 0.6845 - val_loss: 0.7623 - val_accuracy: 0.6951\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7450 - accuracy: 0.6922 - val_loss: 0.7607 - val_accuracy: 0.6951\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7432 - accuracy: 0.6922 - val_loss: 0.7590 - val_accuracy: 0.6951\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7415 - accuracy: 0.6922 - val_loss: 0.7574 - val_accuracy: 0.6977\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7398 - accuracy: 0.6946 - val_loss: 0.7558 - val_accuracy: 0.6977\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7382 - accuracy: 0.6946 - val_loss: 0.7542 - val_accuracy: 0.6977\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7366 - accuracy: 0.6946 - val_loss: 0.7527 - val_accuracy: 0.6977\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7350 - accuracy: 0.6946 - val_loss: 0.7512 - val_accuracy: 0.6977\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7334 - accuracy: 0.6946 - val_loss: 0.7497 - val_accuracy: 0.6977\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7318 - accuracy: 0.6946 - val_loss: 0.7482 - val_accuracy: 0.6977\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7303 - accuracy: 0.6946 - val_loss: 0.7467 - val_accuracy: 0.6977\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7288 - accuracy: 0.6946 - val_loss: 0.7453 - val_accuracy: 0.6977\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7272 - accuracy: 0.6946 - val_loss: 0.7438 - val_accuracy: 0.6977\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7257 - accuracy: 0.6946 - val_loss: 0.7423 - val_accuracy: 0.6977\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7243 - accuracy: 0.6946 - val_loss: 0.7409 - val_accuracy: 0.6977\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7228 - accuracy: 0.6946 - val_loss: 0.7394 - val_accuracy: 0.6977\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7214 - accuracy: 0.6946 - val_loss: 0.7380 - val_accuracy: 0.6977\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7199 - accuracy: 0.6946 - val_loss: 0.7365 - val_accuracy: 0.6977\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7185 - accuracy: 0.6946 - val_loss: 0.7351 - val_accuracy: 0.6977\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7171 - accuracy: 0.6946 - val_loss: 0.7337 - val_accuracy: 0.7154\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7157 - accuracy: 0.7098 - val_loss: 0.7323 - val_accuracy: 0.7154\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7143 - accuracy: 0.7098 - val_loss: 0.7309 - val_accuracy: 0.7154\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7130 - accuracy: 0.7098 - val_loss: 0.7296 - val_accuracy: 0.7289\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7116 - accuracy: 0.7249 - val_loss: 0.7282 - val_accuracy: 0.7294\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7103 - accuracy: 0.7266 - val_loss: 0.7269 - val_accuracy: 0.7294\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7090 - accuracy: 0.7266 - val_loss: 0.7256 - val_accuracy: 0.7434\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7077 - accuracy: 0.7428 - val_loss: 0.7243 - val_accuracy: 0.7434\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7064 - accuracy: 0.7428 - val_loss: 0.7230 - val_accuracy: 0.7434\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7051 - accuracy: 0.7434 - val_loss: 0.7217 - val_accuracy: 0.7577\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7039 - accuracy: 0.7565 - val_loss: 0.7205 - val_accuracy: 0.7577\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7026 - accuracy: 0.7565 - val_loss: 0.7192 - val_accuracy: 0.7577\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7014 - accuracy: 0.7565 - val_loss: 0.7180 - val_accuracy: 0.7577\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7002 - accuracy: 0.7565 - val_loss: 0.7168 - val_accuracy: 0.7577\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6990 - accuracy: 0.7565 - val_loss: 0.7156 - val_accuracy: 0.7577\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6978 - accuracy: 0.7565 - val_loss: 0.7145 - val_accuracy: 0.7577\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6967 - accuracy: 0.7565 - val_loss: 0.7133 - val_accuracy: 0.7577\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6955 - accuracy: 0.7565 - val_loss: 0.7122 - val_accuracy: 0.7577\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6944 - accuracy: 0.7565 - val_loss: 0.7110 - val_accuracy: 0.7577\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6933 - accuracy: 0.7565 - val_loss: 0.7099 - val_accuracy: 0.7577\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6922 - accuracy: 0.7565 - val_loss: 0.7088 - val_accuracy: 0.7580\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6911 - accuracy: 0.7582 - val_loss: 0.7077 - val_accuracy: 0.7580\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6901 - accuracy: 0.7582 - val_loss: 0.7067 - val_accuracy: 0.7580\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6890 - accuracy: 0.7582 - val_loss: 0.7056 - val_accuracy: 0.7580\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6880 - accuracy: 0.7582 - val_loss: 0.7046 - val_accuracy: 0.7580\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6870 - accuracy: 0.7582 - val_loss: 0.7035 - val_accuracy: 0.7580\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.7582 - val_loss: 0.7025 - val_accuracy: 0.7580\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6850 - accuracy: 0.7582 - val_loss: 0.7015 - val_accuracy: 0.7580\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6840 - accuracy: 0.7582 - val_loss: 0.7006 - val_accuracy: 0.7580\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6831 - accuracy: 0.7582 - val_loss: 0.6996 - val_accuracy: 0.7580\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6821 - accuracy: 0.7582 - val_loss: 0.6987 - val_accuracy: 0.7580\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6812 - accuracy: 0.7582 - val_loss: 0.6977 - val_accuracy: 0.7580\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6803 - accuracy: 0.7582 - val_loss: 0.6968 - val_accuracy: 0.7580\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6794 - accuracy: 0.7582 - val_loss: 0.6959 - val_accuracy: 0.7580\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6785 - accuracy: 0.7582 - val_loss: 0.6950 - val_accuracy: 0.7580\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6776 - accuracy: 0.7582 - val_loss: 0.6941 - val_accuracy: 0.7580\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6768 - accuracy: 0.7582 - val_loss: 0.6933 - val_accuracy: 0.7580\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6760 - accuracy: 0.7582 - val_loss: 0.6924 - val_accuracy: 0.7580\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6751 - accuracy: 0.7582 - val_loss: 0.6916 - val_accuracy: 0.7580\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6743 - accuracy: 0.7582 - val_loss: 0.6908 - val_accuracy: 0.7580\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6736 - accuracy: 0.7582 - val_loss: 0.6900 - val_accuracy: 0.7580\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6728 - accuracy: 0.7582 - val_loss: 0.6892 - val_accuracy: 0.7580\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6720 - accuracy: 0.7582 - val_loss: 0.6884 - val_accuracy: 0.7580\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6713 - accuracy: 0.7582 - val_loss: 0.6876 - val_accuracy: 0.7580\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6705 - accuracy: 0.7582 - val_loss: 0.6869 - val_accuracy: 0.7580\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6698 - accuracy: 0.7582 - val_loss: 0.6861 - val_accuracy: 0.7580\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6691 - accuracy: 0.7582 - val_loss: 0.6854 - val_accuracy: 0.7580\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6684 - accuracy: 0.7582 - val_loss: 0.6847 - val_accuracy: 0.7580\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6678 - accuracy: 0.7582 - val_loss: 0.6840 - val_accuracy: 0.7580\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6671 - accuracy: 0.7582 - val_loss: 0.6833 - val_accuracy: 0.7580\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6665 - accuracy: 0.7582 - val_loss: 0.6826 - val_accuracy: 0.7580\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6658 - accuracy: 0.7582 - val_loss: 0.6820 - val_accuracy: 0.7580\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6652 - accuracy: 0.7582 - val_loss: 0.6813 - val_accuracy: 0.7580\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6646 - accuracy: 0.7582 - val_loss: 0.6807 - val_accuracy: 0.7580\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6640 - accuracy: 0.7582 - val_loss: 0.6801 - val_accuracy: 0.7580\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6634 - accuracy: 0.7582 - val_loss: 0.6795 - val_accuracy: 0.7580\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6628 - accuracy: 0.7582 - val_loss: 0.6789 - val_accuracy: 0.7580\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6623 - accuracy: 0.7582 - val_loss: 0.6783 - val_accuracy: 0.7580\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6617 - accuracy: 0.7582 - val_loss: 0.6777 - val_accuracy: 0.7580\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6612 - accuracy: 0.7582 - val_loss: 0.6771 - val_accuracy: 0.7580\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6607 - accuracy: 0.7582 - val_loss: 0.6766 - val_accuracy: 0.7580\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6601 - accuracy: 0.7582 - val_loss: 0.6760 - val_accuracy: 0.7580\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6596 - accuracy: 0.7582 - val_loss: 0.6755 - val_accuracy: 0.7580\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6591 - accuracy: 0.7582 - val_loss: 0.6750 - val_accuracy: 0.7580\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6587 - accuracy: 0.7582 - val_loss: 0.6744 - val_accuracy: 0.7580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6582 - accuracy: 0.7582 - val_loss: 0.6739 - val_accuracy: 0.7580\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6577 - accuracy: 0.7582 - val_loss: 0.6734 - val_accuracy: 0.7580\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6573 - accuracy: 0.7582 - val_loss: 0.6730 - val_accuracy: 0.7580\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6568 - accuracy: 0.7582 - val_loss: 0.6725 - val_accuracy: 0.7580\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6564 - accuracy: 0.7582 - val_loss: 0.6720 - val_accuracy: 0.7580\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6559 - accuracy: 0.7582 - val_loss: 0.6715 - val_accuracy: 0.7580\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6555 - accuracy: 0.7582 - val_loss: 0.6711 - val_accuracy: 0.7580\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6551 - accuracy: 0.7582 - val_loss: 0.6706 - val_accuracy: 0.7580\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6547 - accuracy: 0.7582 - val_loss: 0.6702 - val_accuracy: 0.7580\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6543 - accuracy: 0.7582 - val_loss: 0.6698 - val_accuracy: 0.7580\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6539 - accuracy: 0.7582 - val_loss: 0.6693 - val_accuracy: 0.7514\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6535 - accuracy: 0.7563 - val_loss: 0.6689 - val_accuracy: 0.7514\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6532 - accuracy: 0.7563 - val_loss: 0.6685 - val_accuracy: 0.7514\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6528 - accuracy: 0.7563 - val_loss: 0.6681 - val_accuracy: 0.7514\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6524 - accuracy: 0.7563 - val_loss: 0.6677 - val_accuracy: 0.7586\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6521 - accuracy: 0.7651 - val_loss: 0.6673 - val_accuracy: 0.7586\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6517 - accuracy: 0.7651 - val_loss: 0.6669 - val_accuracy: 0.7586\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6514 - accuracy: 0.7651 - val_loss: 0.6666 - val_accuracy: 0.7586\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6510 - accuracy: 0.7651 - val_loss: 0.6662 - val_accuracy: 0.7586\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6507 - accuracy: 0.7651 - val_loss: 0.6658 - val_accuracy: 0.7586\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6504 - accuracy: 0.7651 - val_loss: 0.6655 - val_accuracy: 0.7586\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6500 - accuracy: 0.7651 - val_loss: 0.6651 - val_accuracy: 0.7586\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6497 - accuracy: 0.7651 - val_loss: 0.6647 - val_accuracy: 0.7586\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6494 - accuracy: 0.7651 - val_loss: 0.6644 - val_accuracy: 0.7586\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6491 - accuracy: 0.7651 - val_loss: 0.6641 - val_accuracy: 0.7586\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6488 - accuracy: 0.7651 - val_loss: 0.6637 - val_accuracy: 0.7586\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6485 - accuracy: 0.7651 - val_loss: 0.6634 - val_accuracy: 0.7586\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6482 - accuracy: 0.7651 - val_loss: 0.6631 - val_accuracy: 0.7586\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6479 - accuracy: 0.7651 - val_loss: 0.6627 - val_accuracy: 0.7586\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6476 - accuracy: 0.7651 - val_loss: 0.6624 - val_accuracy: 0.7586\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6473 - accuracy: 0.7651 - val_loss: 0.6621 - val_accuracy: 0.7586\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6471 - accuracy: 0.7651 - val_loss: 0.6618 - val_accuracy: 0.7586\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6468 - accuracy: 0.7651 - val_loss: 0.6615 - val_accuracy: 0.7586\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6465 - accuracy: 0.7651 - val_loss: 0.6612 - val_accuracy: 0.7586\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6462 - accuracy: 0.7651 - val_loss: 0.6609 - val_accuracy: 0.7586\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6460 - accuracy: 0.7651 - val_loss: 0.6606 - val_accuracy: 0.7586\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6457 - accuracy: 0.7651 - val_loss: 0.6603 - val_accuracy: 0.7586\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6455 - accuracy: 0.7651 - val_loss: 0.6600 - val_accuracy: 0.7586\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6452 - accuracy: 0.7651 - val_loss: 0.6597 - val_accuracy: 0.7586\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6449 - accuracy: 0.7651 - val_loss: 0.6594 - val_accuracy: 0.7586\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6447 - accuracy: 0.7651 - val_loss: 0.6592 - val_accuracy: 0.7586\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6444 - accuracy: 0.7651 - val_loss: 0.6589 - val_accuracy: 0.7586\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6442 - accuracy: 0.7651 - val_loss: 0.6586 - val_accuracy: 0.7586\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6440 - accuracy: 0.7651 - val_loss: 0.6583 - val_accuracy: 0.7586\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6437 - accuracy: 0.7651 - val_loss: 0.6581 - val_accuracy: 0.7586\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6435 - accuracy: 0.7651 - val_loss: 0.6578 - val_accuracy: 0.7586\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6432 - accuracy: 0.7651 - val_loss: 0.6575 - val_accuracy: 0.7586\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6430 - accuracy: 0.7651 - val_loss: 0.6573 - val_accuracy: 0.7586\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6428 - accuracy: 0.7651 - val_loss: 0.6570 - val_accuracy: 0.7586\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6425 - accuracy: 0.7651 - val_loss: 0.6568 - val_accuracy: 0.7586\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6423 - accuracy: 0.7651 - val_loss: 0.6565 - val_accuracy: 0.7586\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6421 - accuracy: 0.7651 - val_loss: 0.6563 - val_accuracy: 0.7586\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6419 - accuracy: 0.7651 - val_loss: 0.6560 - val_accuracy: 0.7586\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6417 - accuracy: 0.7651 - val_loss: 0.6558 - val_accuracy: 0.7586\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6414 - accuracy: 0.7651 - val_loss: 0.6555 - val_accuracy: 0.7586\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6412 - accuracy: 0.7651 - val_loss: 0.6553 - val_accuracy: 0.7586\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6410 - accuracy: 0.7651 - val_loss: 0.6551 - val_accuracy: 0.7586\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6408 - accuracy: 0.7651 - val_loss: 0.6548 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6406 - accuracy: 0.7651 - val_loss: 0.6546 - val_accuracy: 0.7586\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6404 - accuracy: 0.7651 - val_loss: 0.6544 - val_accuracy: 0.7586\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6402 - accuracy: 0.7651 - val_loss: 0.6541 - val_accuracy: 0.7586\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6400 - accuracy: 0.7651 - val_loss: 0.6539 - val_accuracy: 0.7586\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6397 - accuracy: 0.7651 - val_loss: 0.6537 - val_accuracy: 0.7586\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6395 - accuracy: 0.7651 - val_loss: 0.6534 - val_accuracy: 0.7586\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6393 - accuracy: 0.7651 - val_loss: 0.6532 - val_accuracy: 0.7586\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6391 - accuracy: 0.7651 - val_loss: 0.6530 - val_accuracy: 0.7586\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6389 - accuracy: 0.7651 - val_loss: 0.6528 - val_accuracy: 0.7586\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6387 - accuracy: 0.7651 - val_loss: 0.6526 - val_accuracy: 0.7586\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6386 - accuracy: 0.7651 - val_loss: 0.6523 - val_accuracy: 0.7586\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6384 - accuracy: 0.7651 - val_loss: 0.6521 - val_accuracy: 0.7586\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6382 - accuracy: 0.7651 - val_loss: 0.6519 - val_accuracy: 0.7586\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6380 - accuracy: 0.7651 - val_loss: 0.6517 - val_accuracy: 0.7586\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6378 - accuracy: 0.7651 - val_loss: 0.6515 - val_accuracy: 0.7586\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6376 - accuracy: 0.7651 - val_loss: 0.6513 - val_accuracy: 0.7586\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6374 - accuracy: 0.7651 - val_loss: 0.6511 - val_accuracy: 0.7586\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6372 - accuracy: 0.7651 - val_loss: 0.6509 - val_accuracy: 0.7586\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6370 - accuracy: 0.7651 - val_loss: 0.6507 - val_accuracy: 0.7586\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6369 - accuracy: 0.7651 - val_loss: 0.6505 - val_accuracy: 0.7586\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6367 - accuracy: 0.7651 - val_loss: 0.6503 - val_accuracy: 0.7586\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6365 - accuracy: 0.7651 - val_loss: 0.6501 - val_accuracy: 0.7586\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6363 - accuracy: 0.7651 - val_loss: 0.6499 - val_accuracy: 0.7586\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6361 - accuracy: 0.7651 - val_loss: 0.6497 - val_accuracy: 0.7586\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6359 - accuracy: 0.7651 - val_loss: 0.6495 - val_accuracy: 0.7586\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6358 - accuracy: 0.7651 - val_loss: 0.6493 - val_accuracy: 0.7586\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6356 - accuracy: 0.7651 - val_loss: 0.6491 - val_accuracy: 0.7586\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6354 - accuracy: 0.7651 - val_loss: 0.6489 - val_accuracy: 0.7586\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6352 - accuracy: 0.7651 - val_loss: 0.6487 - val_accuracy: 0.7586\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6351 - accuracy: 0.7651 - val_loss: 0.6485 - val_accuracy: 0.7586\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6349 - accuracy: 0.7651 - val_loss: 0.6483 - val_accuracy: 0.7586\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6347 - accuracy: 0.7651 - val_loss: 0.6481 - val_accuracy: 0.7586\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6346 - accuracy: 0.7651 - val_loss: 0.6480 - val_accuracy: 0.7586\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6344 - accuracy: 0.7651 - val_loss: 0.6478 - val_accuracy: 0.7586\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6342 - accuracy: 0.7651 - val_loss: 0.6476 - val_accuracy: 0.7586\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6341 - accuracy: 0.7651 - val_loss: 0.6474 - val_accuracy: 0.7586\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6339 - accuracy: 0.7651 - val_loss: 0.6472 - val_accuracy: 0.7586\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6337 - accuracy: 0.7651 - val_loss: 0.6470 - val_accuracy: 0.7586\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6336 - accuracy: 0.7651 - val_loss: 0.6469 - val_accuracy: 0.7586\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6334 - accuracy: 0.7651 - val_loss: 0.6467 - val_accuracy: 0.7586\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6332 - accuracy: 0.7651 - val_loss: 0.6465 - val_accuracy: 0.7586\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6331 - accuracy: 0.7651 - val_loss: 0.6463 - val_accuracy: 0.7586\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6329 - accuracy: 0.7651 - val_loss: 0.6462 - val_accuracy: 0.7586\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6328 - accuracy: 0.7651 - val_loss: 0.6460 - val_accuracy: 0.7586\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6326 - accuracy: 0.7651 - val_loss: 0.6458 - val_accuracy: 0.7586\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6324 - accuracy: 0.7651 - val_loss: 0.6456 - val_accuracy: 0.7586\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6323 - accuracy: 0.7651 - val_loss: 0.6455 - val_accuracy: 0.7586\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6321 - accuracy: 0.7651 - val_loss: 0.6453 - val_accuracy: 0.7586\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6320 - accuracy: 0.7651 - val_loss: 0.6451 - val_accuracy: 0.7586\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6318 - accuracy: 0.7651 - val_loss: 0.6450 - val_accuracy: 0.7586\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6317 - accuracy: 0.7651 - val_loss: 0.6448 - val_accuracy: 0.7586\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6315 - accuracy: 0.7651 - val_loss: 0.6446 - val_accuracy: 0.7586\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6314 - accuracy: 0.7651 - val_loss: 0.6445 - val_accuracy: 0.7586\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6312 - accuracy: 0.7651 - val_loss: 0.6443 - val_accuracy: 0.7586\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6311 - accuracy: 0.7651 - val_loss: 0.6441 - val_accuracy: 0.7586\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6309 - accuracy: 0.7651 - val_loss: 0.6440 - val_accuracy: 0.7586\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6308 - accuracy: 0.7651 - val_loss: 0.6438 - val_accuracy: 0.7586\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6306 - accuracy: 0.7651 - val_loss: 0.6437 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6305 - accuracy: 0.7651 - val_loss: 0.6435 - val_accuracy: 0.7586\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6303 - accuracy: 0.7651 - val_loss: 0.6433 - val_accuracy: 0.7586\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6302 - accuracy: 0.7651 - val_loss: 0.6432 - val_accuracy: 0.7586\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6301 - accuracy: 0.7651 - val_loss: 0.6430 - val_accuracy: 0.7586\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6299 - accuracy: 0.7651 - val_loss: 0.6429 - val_accuracy: 0.7586\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6298 - accuracy: 0.7651 - val_loss: 0.6427 - val_accuracy: 0.7586\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6296 - accuracy: 0.7651 - val_loss: 0.6426 - val_accuracy: 0.7586\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6295 - accuracy: 0.7651 - val_loss: 0.6424 - val_accuracy: 0.7586\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6294 - accuracy: 0.7651 - val_loss: 0.6423 - val_accuracy: 0.7586\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6292 - accuracy: 0.7651 - val_loss: 0.6421 - val_accuracy: 0.7586\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6291 - accuracy: 0.7651 - val_loss: 0.6420 - val_accuracy: 0.7586\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6289 - accuracy: 0.7651 - val_loss: 0.6418 - val_accuracy: 0.7586\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6288 - accuracy: 0.7651 - val_loss: 0.6417 - val_accuracy: 0.7586\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6287 - accuracy: 0.7651 - val_loss: 0.6415 - val_accuracy: 0.7586\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6285 - accuracy: 0.7651 - val_loss: 0.6414 - val_accuracy: 0.7586\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6284 - accuracy: 0.7651 - val_loss: 0.6412 - val_accuracy: 0.7586\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6283 - accuracy: 0.7651 - val_loss: 0.6411 - val_accuracy: 0.7586\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6281 - accuracy: 0.7651 - val_loss: 0.6409 - val_accuracy: 0.7586\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6280 - accuracy: 0.7651 - val_loss: 0.6408 - val_accuracy: 0.7586\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6279 - accuracy: 0.7651 - val_loss: 0.6406 - val_accuracy: 0.7586\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6277 - accuracy: 0.7651 - val_loss: 0.6405 - val_accuracy: 0.7586\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6276 - accuracy: 0.7651 - val_loss: 0.6404 - val_accuracy: 0.7586\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6275 - accuracy: 0.7651 - val_loss: 0.6402 - val_accuracy: 0.7586\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6274 - accuracy: 0.7651 - val_loss: 0.6401 - val_accuracy: 0.7586\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6272 - accuracy: 0.7651 - val_loss: 0.6400 - val_accuracy: 0.7586\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6271 - accuracy: 0.7651 - val_loss: 0.6398 - val_accuracy: 0.7586\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6270 - accuracy: 0.7651 - val_loss: 0.6397 - val_accuracy: 0.7586\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6269 - accuracy: 0.7651 - val_loss: 0.6395 - val_accuracy: 0.7586\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6267 - accuracy: 0.7651 - val_loss: 0.6394 - val_accuracy: 0.7586\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6266 - accuracy: 0.7651 - val_loss: 0.6393 - val_accuracy: 0.7586\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6265 - accuracy: 0.7651 - val_loss: 0.6391 - val_accuracy: 0.7586\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6264 - accuracy: 0.7651 - val_loss: 0.6390 - val_accuracy: 0.7586\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6262 - accuracy: 0.7651 - val_loss: 0.6389 - val_accuracy: 0.7586\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6261 - accuracy: 0.7651 - val_loss: 0.6387 - val_accuracy: 0.7586\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6260 - accuracy: 0.7651 - val_loss: 0.6386 - val_accuracy: 0.7586\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6259 - accuracy: 0.7651 - val_loss: 0.6385 - val_accuracy: 0.7586\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6258 - accuracy: 0.7651 - val_loss: 0.6384 - val_accuracy: 0.7586\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6256 - accuracy: 0.7651 - val_loss: 0.6382 - val_accuracy: 0.7586\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6255 - accuracy: 0.7651 - val_loss: 0.6381 - val_accuracy: 0.7586\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6254 - accuracy: 0.7651 - val_loss: 0.6380 - val_accuracy: 0.7586\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6253 - accuracy: 0.7651 - val_loss: 0.6378 - val_accuracy: 0.7586\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6252 - accuracy: 0.7651 - val_loss: 0.6377 - val_accuracy: 0.7586\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6251 - accuracy: 0.7651 - val_loss: 0.6376 - val_accuracy: 0.7586\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6249 - accuracy: 0.7651 - val_loss: 0.6375 - val_accuracy: 0.7586\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6248 - accuracy: 0.7651 - val_loss: 0.6373 - val_accuracy: 0.7586\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6247 - accuracy: 0.7651 - val_loss: 0.6372 - val_accuracy: 0.7586\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6246 - accuracy: 0.7651 - val_loss: 0.6371 - val_accuracy: 0.7586\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6245 - accuracy: 0.7651 - val_loss: 0.6370 - val_accuracy: 0.7586\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6244 - accuracy: 0.7651 - val_loss: 0.6369 - val_accuracy: 0.7586\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6243 - accuracy: 0.7651 - val_loss: 0.6367 - val_accuracy: 0.7586\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6242 - accuracy: 0.7651 - val_loss: 0.6366 - val_accuracy: 0.7586\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6241 - accuracy: 0.7651 - val_loss: 0.6365 - val_accuracy: 0.7586\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6239 - accuracy: 0.7651 - val_loss: 0.6364 - val_accuracy: 0.7586\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6238 - accuracy: 0.7651 - val_loss: 0.6363 - val_accuracy: 0.7586\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6237 - accuracy: 0.7651 - val_loss: 0.6362 - val_accuracy: 0.7586\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6236 - accuracy: 0.7651 - val_loss: 0.6360 - val_accuracy: 0.7586\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6235 - accuracy: 0.7651 - val_loss: 0.6359 - val_accuracy: 0.7586\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6234 - accuracy: 0.7651 - val_loss: 0.6358 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6233 - accuracy: 0.7651 - val_loss: 0.6357 - val_accuracy: 0.7586\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6232 - accuracy: 0.7651 - val_loss: 0.6356 - val_accuracy: 0.7586\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6231 - accuracy: 0.7651 - val_loss: 0.6355 - val_accuracy: 0.7586\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6230 - accuracy: 0.7651 - val_loss: 0.6354 - val_accuracy: 0.7586\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6229 - accuracy: 0.7651 - val_loss: 0.6353 - val_accuracy: 0.7586\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6228 - accuracy: 0.7651 - val_loss: 0.6351 - val_accuracy: 0.7586\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6227 - accuracy: 0.7651 - val_loss: 0.6350 - val_accuracy: 0.7586\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6226 - accuracy: 0.7651 - val_loss: 0.6349 - val_accuracy: 0.7586\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6225 - accuracy: 0.7651 - val_loss: 0.6348 - val_accuracy: 0.7586\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6224 - accuracy: 0.7651 - val_loss: 0.6347 - val_accuracy: 0.7586\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6223 - accuracy: 0.7651 - val_loss: 0.6346 - val_accuracy: 0.7586\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6222 - accuracy: 0.7651 - val_loss: 0.6345 - val_accuracy: 0.7586\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6221 - accuracy: 0.7651 - val_loss: 0.6344 - val_accuracy: 0.7586\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6220 - accuracy: 0.7651 - val_loss: 0.6343 - val_accuracy: 0.7586\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6219 - accuracy: 0.7651 - val_loss: 0.6342 - val_accuracy: 0.7586\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6218 - accuracy: 0.7651 - val_loss: 0.6341 - val_accuracy: 0.7586\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6217 - accuracy: 0.7651 - val_loss: 0.6340 - val_accuracy: 0.7586\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6216 - accuracy: 0.7651 - val_loss: 0.6339 - val_accuracy: 0.7586\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6215 - accuracy: 0.7651 - val_loss: 0.6338 - val_accuracy: 0.7586\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6214 - accuracy: 0.7651 - val_loss: 0.6337 - val_accuracy: 0.7586\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6213 - accuracy: 0.7651 - val_loss: 0.6336 - val_accuracy: 0.7586\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6213 - accuracy: 0.7651 - val_loss: 0.6335 - val_accuracy: 0.7586\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6212 - accuracy: 0.7651 - val_loss: 0.6334 - val_accuracy: 0.7586\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6211 - accuracy: 0.7651 - val_loss: 0.6333 - val_accuracy: 0.7586\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6210 - accuracy: 0.7651 - val_loss: 0.6332 - val_accuracy: 0.7586\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6209 - accuracy: 0.7651 - val_loss: 0.6331 - val_accuracy: 0.7586\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6208 - accuracy: 0.7651 - val_loss: 0.6330 - val_accuracy: 0.7586\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6207 - accuracy: 0.7651 - val_loss: 0.6329 - val_accuracy: 0.7586\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6206 - accuracy: 0.7651 - val_loss: 0.6328 - val_accuracy: 0.7586\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6205 - accuracy: 0.7651 - val_loss: 0.6327 - val_accuracy: 0.7586\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6204 - accuracy: 0.7651 - val_loss: 0.6326 - val_accuracy: 0.7586\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6204 - accuracy: 0.7651 - val_loss: 0.6325 - val_accuracy: 0.7586\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6203 - accuracy: 0.7651 - val_loss: 0.6324 - val_accuracy: 0.7586\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6202 - accuracy: 0.7651 - val_loss: 0.6323 - val_accuracy: 0.7586\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6201 - accuracy: 0.7651 - val_loss: 0.6322 - val_accuracy: 0.7586\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6200 - accuracy: 0.7651 - val_loss: 0.6321 - val_accuracy: 0.7586\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6199 - accuracy: 0.7651 - val_loss: 0.6320 - val_accuracy: 0.7586\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6198 - accuracy: 0.7651 - val_loss: 0.6319 - val_accuracy: 0.7586\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6198 - accuracy: 0.7651 - val_loss: 0.6318 - val_accuracy: 0.7586\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6197 - accuracy: 0.7651 - val_loss: 0.6318 - val_accuracy: 0.7586\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6196 - accuracy: 0.7651 - val_loss: 0.6317 - val_accuracy: 0.7586\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6195 - accuracy: 0.7651 - val_loss: 0.6316 - val_accuracy: 0.7586\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6194 - accuracy: 0.7651 - val_loss: 0.6315 - val_accuracy: 0.7586\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6193 - accuracy: 0.7651 - val_loss: 0.6314 - val_accuracy: 0.7586\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6193 - accuracy: 0.7651 - val_loss: 0.6313 - val_accuracy: 0.7586\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6192 - accuracy: 0.7651 - val_loss: 0.6312 - val_accuracy: 0.7586\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6191 - accuracy: 0.7651 - val_loss: 0.6311 - val_accuracy: 0.7586\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6190 - accuracy: 0.7651 - val_loss: 0.6311 - val_accuracy: 0.7586\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6189 - accuracy: 0.7651 - val_loss: 0.6310 - val_accuracy: 0.7586\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6189 - accuracy: 0.7651 - val_loss: 0.6309 - val_accuracy: 0.7586\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6188 - accuracy: 0.7651 - val_loss: 0.6308 - val_accuracy: 0.7586\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6187 - accuracy: 0.7651 - val_loss: 0.6307 - val_accuracy: 0.7586\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6186 - accuracy: 0.7651 - val_loss: 0.6306 - val_accuracy: 0.7586\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6186 - accuracy: 0.7651 - val_loss: 0.6305 - val_accuracy: 0.7586\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6185 - accuracy: 0.7651 - val_loss: 0.6305 - val_accuracy: 0.7586\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6184 - accuracy: 0.7651 - val_loss: 0.6304 - val_accuracy: 0.7586\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6183 - accuracy: 0.7651 - val_loss: 0.6303 - val_accuracy: 0.7586\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6183 - accuracy: 0.7651 - val_loss: 0.6302 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6182 - accuracy: 0.7651 - val_loss: 0.6301 - val_accuracy: 0.7586\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6181 - accuracy: 0.7651 - val_loss: 0.6301 - val_accuracy: 0.7586\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6180 - accuracy: 0.7651 - val_loss: 0.6300 - val_accuracy: 0.7586\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6180 - accuracy: 0.7651 - val_loss: 0.6299 - val_accuracy: 0.7586\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6179 - accuracy: 0.7651 - val_loss: 0.6298 - val_accuracy: 0.7586\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6178 - accuracy: 0.7651 - val_loss: 0.6297 - val_accuracy: 0.7586\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6177 - accuracy: 0.7651 - val_loss: 0.6297 - val_accuracy: 0.7586\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6177 - accuracy: 0.7651 - val_loss: 0.6296 - val_accuracy: 0.7586\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6176 - accuracy: 0.7651 - val_loss: 0.6295 - val_accuracy: 0.7586\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6175 - accuracy: 0.7651 - val_loss: 0.6294 - val_accuracy: 0.7586\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6175 - accuracy: 0.7651 - val_loss: 0.6294 - val_accuracy: 0.7586\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6174 - accuracy: 0.7651 - val_loss: 0.6293 - val_accuracy: 0.7586\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6173 - accuracy: 0.7651 - val_loss: 0.6292 - val_accuracy: 0.7586\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6173 - accuracy: 0.7651 - val_loss: 0.6291 - val_accuracy: 0.7586\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6172 - accuracy: 0.7651 - val_loss: 0.6291 - val_accuracy: 0.7586\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6171 - accuracy: 0.7651 - val_loss: 0.6290 - val_accuracy: 0.7586\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6170 - accuracy: 0.7651 - val_loss: 0.6289 - val_accuracy: 0.7586\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6170 - accuracy: 0.7651 - val_loss: 0.6288 - val_accuracy: 0.7586\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6169 - accuracy: 0.7651 - val_loss: 0.6288 - val_accuracy: 0.7586\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6168 - accuracy: 0.7651 - val_loss: 0.6287 - val_accuracy: 0.7586\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6168 - accuracy: 0.7651 - val_loss: 0.6286 - val_accuracy: 0.7586\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6167 - accuracy: 0.7651 - val_loss: 0.6285 - val_accuracy: 0.7586\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6166 - accuracy: 0.7651 - val_loss: 0.6285 - val_accuracy: 0.7586\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6166 - accuracy: 0.7651 - val_loss: 0.6284 - val_accuracy: 0.7586\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6165 - accuracy: 0.7651 - val_loss: 0.6283 - val_accuracy: 0.7586\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6165 - accuracy: 0.7651 - val_loss: 0.6283 - val_accuracy: 0.7586\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6164 - accuracy: 0.7651 - val_loss: 0.6282 - val_accuracy: 0.7586\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6163 - accuracy: 0.7651 - val_loss: 0.6281 - val_accuracy: 0.7586\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6163 - accuracy: 0.7651 - val_loss: 0.6281 - val_accuracy: 0.7586\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6162 - accuracy: 0.7651 - val_loss: 0.6280 - val_accuracy: 0.7586\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6161 - accuracy: 0.7651 - val_loss: 0.6279 - val_accuracy: 0.7586\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6161 - accuracy: 0.7651 - val_loss: 0.6279 - val_accuracy: 0.7586\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6160 - accuracy: 0.7651 - val_loss: 0.6278 - val_accuracy: 0.7586\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6160 - accuracy: 0.7651 - val_loss: 0.6277 - val_accuracy: 0.7586\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6159 - accuracy: 0.7651 - val_loss: 0.6277 - val_accuracy: 0.7586\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6158 - accuracy: 0.7651 - val_loss: 0.6276 - val_accuracy: 0.7586\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6158 - accuracy: 0.7651 - val_loss: 0.6275 - val_accuracy: 0.7586\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6157 - accuracy: 0.7651 - val_loss: 0.6275 - val_accuracy: 0.7586\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6157 - accuracy: 0.7651 - val_loss: 0.6274 - val_accuracy: 0.7586\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6156 - accuracy: 0.7651 - val_loss: 0.6273 - val_accuracy: 0.7586\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6155 - accuracy: 0.7651 - val_loss: 0.6273 - val_accuracy: 0.7586\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6155 - accuracy: 0.7651 - val_loss: 0.6272 - val_accuracy: 0.7586\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6154 - accuracy: 0.7651 - val_loss: 0.6271 - val_accuracy: 0.7586\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6154 - accuracy: 0.7651 - val_loss: 0.6271 - val_accuracy: 0.7586\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6153 - accuracy: 0.7651 - val_loss: 0.6270 - val_accuracy: 0.7586\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6152 - accuracy: 0.7651 - val_loss: 0.6269 - val_accuracy: 0.7586\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6152 - accuracy: 0.7651 - val_loss: 0.6269 - val_accuracy: 0.7586\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6151 - accuracy: 0.7651 - val_loss: 0.6268 - val_accuracy: 0.7586\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6151 - accuracy: 0.7651 - val_loss: 0.6268 - val_accuracy: 0.7586\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6150 - accuracy: 0.7651 - val_loss: 0.6267 - val_accuracy: 0.7586\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6150 - accuracy: 0.7651 - val_loss: 0.6266 - val_accuracy: 0.7586\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6149 - accuracy: 0.7651 - val_loss: 0.6266 - val_accuracy: 0.7586\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6148 - accuracy: 0.7651 - val_loss: 0.6265 - val_accuracy: 0.7586\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6148 - accuracy: 0.7651 - val_loss: 0.6265 - val_accuracy: 0.7586\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6147 - accuracy: 0.7651 - val_loss: 0.6264 - val_accuracy: 0.7586\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6147 - accuracy: 0.7651 - val_loss: 0.6263 - val_accuracy: 0.7586\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6146 - accuracy: 0.7651 - val_loss: 0.6263 - val_accuracy: 0.7586\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6146 - accuracy: 0.7651 - val_loss: 0.6262 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6145 - accuracy: 0.7651 - val_loss: 0.6262 - val_accuracy: 0.7586\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6145 - accuracy: 0.7651 - val_loss: 0.6261 - val_accuracy: 0.7586\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6144 - accuracy: 0.7651 - val_loss: 0.6261 - val_accuracy: 0.7586\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6144 - accuracy: 0.7651 - val_loss: 0.6260 - val_accuracy: 0.7586\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6143 - accuracy: 0.7651 - val_loss: 0.6259 - val_accuracy: 0.7586\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6143 - accuracy: 0.7651 - val_loss: 0.6259 - val_accuracy: 0.7586\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6142 - accuracy: 0.7651 - val_loss: 0.6258 - val_accuracy: 0.7586\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6142 - accuracy: 0.7651 - val_loss: 0.6258 - val_accuracy: 0.7586\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6141 - accuracy: 0.7651 - val_loss: 0.6257 - val_accuracy: 0.7586\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6141 - accuracy: 0.7651 - val_loss: 0.6257 - val_accuracy: 0.7586\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6140 - accuracy: 0.7651 - val_loss: 0.6256 - val_accuracy: 0.7586\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6140 - accuracy: 0.7651 - val_loss: 0.6256 - val_accuracy: 0.7586\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6139 - accuracy: 0.7651 - val_loss: 0.6255 - val_accuracy: 0.7586\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6139 - accuracy: 0.7651 - val_loss: 0.6254 - val_accuracy: 0.7586\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6138 - accuracy: 0.7651 - val_loss: 0.6254 - val_accuracy: 0.7586\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6138 - accuracy: 0.7651 - val_loss: 0.6253 - val_accuracy: 0.7586\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6137 - accuracy: 0.7651 - val_loss: 0.6253 - val_accuracy: 0.7586\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6137 - accuracy: 0.7651 - val_loss: 0.6252 - val_accuracy: 0.7586\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6136 - accuracy: 0.7651 - val_loss: 0.6252 - val_accuracy: 0.7586\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6136 - accuracy: 0.7651 - val_loss: 0.6251 - val_accuracy: 0.7586\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6135 - accuracy: 0.7651 - val_loss: 0.6251 - val_accuracy: 0.7586\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6135 - accuracy: 0.7651 - val_loss: 0.6250 - val_accuracy: 0.7586\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6134 - accuracy: 0.7651 - val_loss: 0.6250 - val_accuracy: 0.7586\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6134 - accuracy: 0.7651 - val_loss: 0.6249 - val_accuracy: 0.7586\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6133 - accuracy: 0.7651 - val_loss: 0.6249 - val_accuracy: 0.7586\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6133 - accuracy: 0.7651 - val_loss: 0.6248 - val_accuracy: 0.7586\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6132 - accuracy: 0.7651 - val_loss: 0.6248 - val_accuracy: 0.7586\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6132 - accuracy: 0.7651 - val_loss: 0.6247 - val_accuracy: 0.7586\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6131 - accuracy: 0.7651 - val_loss: 0.6247 - val_accuracy: 0.7586\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6131 - accuracy: 0.7651 - val_loss: 0.6246 - val_accuracy: 0.7586\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6131 - accuracy: 0.7651 - val_loss: 0.6246 - val_accuracy: 0.7586\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6130 - accuracy: 0.7651 - val_loss: 0.6245 - val_accuracy: 0.7586\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6130 - accuracy: 0.7651 - val_loss: 0.6245 - val_accuracy: 0.7586\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6129 - accuracy: 0.7651 - val_loss: 0.6244 - val_accuracy: 0.7586\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.7651 - val_loss: 0.6244 - val_accuracy: 0.7586\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6128 - accuracy: 0.7651 - val_loss: 0.6243 - val_accuracy: 0.7586\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.613\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.4,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x. Obtain behavioural insights into the Willingness-to-Pay for storage space:\n",
    "- (1) Compute WtP for extra storage space from MNL part of the model\n",
    "- (2) Derive insights into the importance of extra storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Compute WtP for extra storage from MNL part of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_COST    =  -1.105\n",
      "Beta_STORAGE =  0.518\n",
      "WtP storage  =  0.47  per extra Gigabite\n",
      "\n",
      "Cross-entropy training data at final epoch  =  0.613\n",
      "Log-likelihood training data at final epoch =  -3983.4\n",
      "rho square training data at final epoch     =  0.44\n",
      "\n",
      "Cross-entropy test data at final epoch     =  0.624\n",
      "Log-likelihood test data at final epoch    =  -2185.2\n",
      "rho square test data at final epoch        =  0.43\n"
     ]
    }
   ],
   "source": [
    "# Show the trained taste parameters, from the MNL part\n",
    "beta_COST = np.squeeze((betas[0][0]))\n",
    "beta_STORAGE = np.squeeze((betas[0][1]))\n",
    "print('Beta_COST    = ', \"{:.3f}\".format(beta_COST )) \n",
    "print('Beta_STORAGE = ', \"{:.3f}\".format(beta_STORAGE ))\n",
    "\n",
    "# Compute the Willingness to Pay for a Gb extra storage space\n",
    "WtP_storage = -beta_STORAGE/beta_COST\n",
    "print('WtP storage  = ', \"{:.2f}\".format(WtP_storage),' per extra Gigabite')\n",
    "print()\n",
    "\n",
    "# For comparison convert the loss to log-likelihood and rho^2\n",
    "hist_loss_train = history.history.get('loss')\n",
    "LL_final_train = -np.array(hist_loss_train[len(hist_loss_train)-1]) *len(Y_train)\n",
    "print('Cross-entropy training data at final epoch  = ', \"{:.3f}\".format(hist_loss_train[len(hist_loss_train)-1]))\n",
    "print('Log-likelihood training data at final epoch = ', \"{:.1f}\".format(LL_final_train))\n",
    "print('rho square training data at final epoch     = ', \"{:.2f}\".format(1 - LL_final_train / -(len(Y_train)*np.log(3))))\n",
    "print()\n",
    "\n",
    "hist_loss_test = history.history.get('val_loss')\n",
    "LL_final_test = -np.array(hist_loss_test[len(hist_loss_test)-1]) *len(Y_test)\n",
    "print('Cross-entropy test data at final epoch     = ', \"{:.3f}\".format(hist_loss_test[len(hist_loss_test)-1]))\n",
    "print('Log-likelihood test data at final epoch    = ', \"{:.1f}\".format(LL_final_test))\n",
    "print('rho square test data at final epoch        = ', \"{:.2f}\".format(1 - LL_final_test / -(len(Y_test)*np.log(3))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Derive insights into the importance of extra storage from ANN part of the model by re-doing the analysis we did in lecture 1.<br>\n",
    "\n",
    "\n",
    "That is, let's simulate the effect of a (change in) attribute levels of STORAGE on the choice probabilities.\n",
    "\n",
    "To do so, we take the following steps:\n",
    " 1. Create an ndarray containing the following alternatives. Use Male (GENDER=0) and Income level 2 (INC=2)for the socio-demographic variables\n",
    " 2. Apply the trained ANN to these data points. \n",
    " 3. Plot the effect of the STORAGE of alternative 3 on the choice probabilities that alternatives 1,2, 3 are choosen for a Male with Income level 2.\n",
    "\n",
    "\n",
    "| COST_1 | SIZE_1 | STORAGE_1 | CAM_1 | COST_2 | SIZE_2 | STORAGE_2 | CAM_2 | COST_3 | SIZE_3 | STORAGE_3 | CAM_3 |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **32**  | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **64**  | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **128** | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **256** | 2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (4, 2, 3, 1)\n",
      "Shape of x_ann (4, 8)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create an ndarray containing the alternatives in the table above\n",
    "X_sim = np.array([[500,6.0,64,2,500,6.0,64,2,500,6.0,32,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,64,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,128,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,256,2,0,2]])\n",
    "\n",
    "# Step 2: Apply the trained ANN to these data points\n",
    "# Rescale input data using the same scaler as used for training\n",
    "# MNL input\n",
    "scale = 100\n",
    "x_mnl_sim = np.array([[np.divide(X_sim[:,0], scale), np.divide(X_sim[:,2], scale)],\n",
    "                      [np.divide(X_sim[:,4], scale), np.divide(X_sim[:,6], scale)],\n",
    "                      [np.divide(X_sim[:,8], scale), np.divide(X_sim[:,10], scale)]])\n",
    "x_mnl_sim = np.swapaxes(x_mnl_sim, 0, 2)\n",
    "x_mnl_sim = np.expand_dims(x_mnl_sim, 3)\n",
    "print('Shape of x_mnl', x_mnl_sim.shape)\n",
    "\n",
    "# ANN input\n",
    "x_ann_sim = np.array([[X_sim[:,1], X_sim[:,3], X_sim[:,5], X_sim[:,7], X_sim[:,9], X_sim[:,11], np.zeros(4), 2*np.ones(4)]])\n",
    "x_ann_sim = np.squeeze(np.swapaxes(x_ann_sim, 0, 2))\n",
    "x_ann_sim = scaler.transform(x_ann_sim)  \n",
    "print('Shape of x_ann', x_ann_sim.shape)\n",
    "\n",
    "# Simulate the choice probabilities by applying the trained model\n",
    "probs_x_sim = model.predict([x_mnl_sim, x_ann_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x640 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Plot the effect of the STORAGE of alternative 3 on the choice probabilities\n",
    "# Plot the outputs\n",
    "fig=plt.figure(figsize=(12,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(221)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,probs_x_sim[:,0], label = \"Probability alternative 1\")\n",
    "plt.plot(x_levels,probs_x_sim[:,1], label = \"Probability alternative 2\")\n",
    "plt.plot(x_levels,probs_x_sim[:,2], label = \"Probability alternative 3\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('Hybrid model')\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlim([0, 260])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.subplot(223)\n",
    "utility_ANN_X_sim_V1 = 0 # As utilities are not absolute, we can arbitrarily fix V1 to zero\n",
    "utility_ANN_X_sim_V2 = np.log(probs_x_sim[:,1]/probs_x_sim[:,0]) # Utility of alternative 2 relative to V1\n",
    "utility_ANN_X_sim_V3 = np.log(probs_x_sim[:,2]/probs_x_sim[:,0]) # Utility of alternative 3 relative to V1\n",
    "plt.plot(x_levels,np.tile(utility_ANN_X_sim_V1,(len(x_levels))), label = \"Utility alternative 1\")\n",
    "plt.plot(x_levels,utility_ANN_X_sim_V2,                          label = \"Utility alternative 2\")\n",
    "plt.plot(x_levels,utility_ANN_X_sim_V3,                          label = \"Utility alternative 3\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('Hybrid model')\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlim([0,260])\n",
    "\n",
    "# For comparison we also add the plots for the DCM\n",
    "betas_DCM = {\"B_camera\": 0.812309,\"B_cost\":-0.010879,\"B_size\":2.106680,\"B_storage\":0.004567} # These are the beta estimates of exercise 1\n",
    "\n",
    "# Compute utility using the estimated betas\n",
    "V1_X_sim = betas_DCM['B_cost']*X_sim[:,0] + betas_DCM['B_size']*X_sim[:,1] + betas_DCM['B_storage']*X_sim[:,2] + betas_DCM['B_camera']*X_sim[:,3]\n",
    "V2_X_sim = betas_DCM['B_cost']*X_sim[:,4] + betas_DCM['B_size']*X_sim[:,5] + betas_DCM['B_storage']*X_sim[:,6] + betas_DCM['B_camera']*X_sim[:,7]\n",
    "V3_X_sim = betas_DCM['B_cost']*X_sim[:,8] + betas_DCM['B_size']*X_sim[:,9] + betas_DCM['B_storage']*X_sim[:,10] + betas_DCM['B_camera']*X_sim[:,11]\n",
    "\n",
    "# Compute probabilities\n",
    "P1_sim = np.exp(V1_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P2_sim = np.exp(V2_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P3_sim = np.exp(V3_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P_sim = np.transpose([P1_sim, P2_sim, P3_sim])\n",
    "\n",
    "plt.subplot(222)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,P_sim[:,0], label= \"Probability alternative 1\")\n",
    "plt.plot(x_levels,P_sim[:,1], label= \"Probability alternative 2\")\n",
    "plt.plot(x_levels,P_sim[:,2], label= \"Probability alternative 3\")\n",
    "plt.title('Discrete choice model exercise 1')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlim([0,260])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.subplot(224)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,V1_X_sim-V1_X_sim, label= \"Utility alternative 1\")\n",
    "plt.plot(x_levels,V2_X_sim-V1_X_sim, label= \"Utility alternative 2\")\n",
    "plt.plot(x_levels,V3_X_sim-V1_X_sim, label= \"Utility alternative 3\")\n",
    "plt.title('Discrete choice model exercise 1')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlim([0,260])\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1. Compare these plots with those found in exercise 2 (lecture 1). What catches the eye? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2. Compare the model performance, the estimates, and no. weights between this hybrid model, and those of the DCM and ANN of lecture 1. Explain why these results are in line with expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "026be6e5a1123b745c834c4f20bb4e6186274d8f23878cd8715984c0247c49fb"
  },
  "kernelspec": {
   "display_name": "Python3.9 (uyui)",
   "language": "python",
   "name": "uyui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
