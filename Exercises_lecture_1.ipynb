{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Lecture 1\n",
    "**6 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh\n",
    "- Francisco Garrido-Valenzuela\n",
    "\n",
    "**This notebook will not be graded. You do not have to submit the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "### Using Colab\n",
    "\n",
    "Students using **Colab**, just need to install **Biogeme**. Biogeme is a Python package designed for the maximum likelihood estimation of parametric models in general, with a special emphasis on discrete choice models. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/exercises\n",
    "#root = 'exercises/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "#!pip3 install -r requirements.txt\n",
    "#root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Exercise 1: My first discrete choice model\n",
    "\n",
    "**Objective:**  Acquire a basic understanding of and feeling for choice behaviour modelling \n",
    "\n",
    "### i. import Python packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Load the data and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to csv database \n",
    "db_file = f'{root}datasets/dcm/smartphone_choicedata2021.csv'\n",
    "\n",
    "# Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "df = pd.read_csv(db_file, sep='\\t')\n",
    "database = db.Database('smartphone_choicedata2021', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Inspect the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how often each alternative is chosen\n",
    "fig=plt.figure(figsize=(6,4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(df.CHOICE, bins = [0.75, 1.25, 1.75, 2.25, 2.75, 3.25])\n",
    "plt.xticks((1, 2, 3))\n",
    "plt.title('Number of choices per alternative')\n",
    "plt.xlabel('Choice')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1. Do you have a feeling for the data set?, i.e.\n",
    "- #### (a) Do you understand all features, and their levels?\n",
    "- #### (b) Are the output class labels nicely balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    \n",
    "**ANSWER**\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Declaring the parameters of the discrete choice model to be estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we declare which parameters of the discrete choice model need to be estimated using the *Beta* syntax. <br>\n",
    "For each parameter we declare its:\n",
    "* *name* for latter use. \n",
    "* *starting value* for the numerical optimisation. Usually 0.\n",
    "* *lower bound* Constrain the estimate to be larger  than e.g. 0. Use \"None\" if there is no lower bound constraint.\n",
    "* *upper bound* Constrain the estimate to be smaller than e.g. 1. Use \"None\" if there is no upper bound constraint.\n",
    "* *status* Declares wheter the parameter needs to be estimated. 0 = estimate, 1 = fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_cost = Beta('B_cost', 0, None, None, 0)\n",
    "B_size = Beta('B_size', 0, None, None, 0)\n",
    "B_storage = Beta('B_storage', 0, None, None, 0)\n",
    "B_camera = Beta('B_camera', 0, None, None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. The utility function\n",
    "Here we define the utility function. This function postulates how the decision makers, *n*, experience utility, *U*, for alternatives, *i*, presented to them. <br> Part of the utility experienced is due to factors observable to the analyst; part is due to unobservable factors: \n",
    "\n",
    "$ U_{in} = V_{in} + \\epsilon_{in}$. <br> \n",
    "\n",
    "Commonly the observable part utility *V* is postulated to be linear-additive: \n",
    "\n",
    "$ V_{in} = \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "Finally, note that it is common to assume that the utility function is the same for all decision makers *n*. Therefore *n* drops from the utility specification. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "V1 = B_cost * COST_1 + B_size * SIZE_1 + B_storage * STORAGE_1 + B_camera * CAM_1\n",
    "V2 = B_cost * COST_2 + B_size * SIZE_2 + B_storage * STORAGE_2 + B_camera * CAM_2\n",
    "V3 = B_cost * COST_3 + B_size * SIZE_3 + B_storage * STORAGE_3 + B_camera * CAM_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we associate the defined utility functions with the numering of the alternatives in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Availability of alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we declare which alternatives are available (i.e. present to the decision maker and feasible to choose) in a choice task. This availability is defined by a variable *AVAIL_* in the data, where: <br>\n",
    "* *AVAIL_* = 1 means the alternative is available\n",
    "* *AVAIL_* = 0 means the alternative is unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the availability conditions with the alternatives\n",
    "av = {1: AVAIL_1, 2: AVAIL_2, 3: AVAIL_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii. Estimate the discrete choice model\n",
    "Next we estimate the discrete choice model. That is, we **maximise** the **likelihood of the data** (i.e. the choices made) given the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, prob)\n",
    "biogeme.modelName = 'My first discrete choice model'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "pandasResults = results.getEstimatedParameters()\n",
    "print(pandasResults[['Value','Std err','t-test','p-value']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2. Interpret the estimated parameters\n",
    "- #### (a) Do the parameters have the expected sign? Explain your answer.\n",
    "- #### (b) What units do the betas have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER**\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viii. Compute Willingness-to-Pay estimates\n",
    "Under the assumption that utility is linear-additive we can straightforwardly compute the Willingness-to-Pay estimates, by evaluating their ratios. These WtP estimates give the *average* willingness to pay across the sampled population. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results in a pandas table\n",
    "print('Willingness-to-Pay estimates')\n",
    "print('----------')\n",
    "betas = results.getBetaValues()\n",
    "WtP_storage = betas['B_storage']/-betas['B_cost']\n",
    "WtP_size = betas['B_size']/-betas['B_cost']\n",
    "WtP_camera = betas['B_camera']/-betas['B_cost']\n",
    "\n",
    "print('Willingness to Pay estimate for Storage         = €', \"{:.2f}\".format(WtP_storage),'   per extra Gigabite')\n",
    "print('Willingness to Pay estimate for Size            = €', \"{:.2f}\".format(WtP_size),' per extra diagonal inch')\n",
    "print('Willingness to Pay estimate for Camera quality  = €', \"{:.2f}\".format(WtP_camera),'  per unit quality level improvement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a smartphone maker is considering to bring one of two smartphone model to the market.\n",
    "Per sold item both models yield the same profit. So, the most profitable model is the one that sells best.\n",
    "We can use the **WtP** estimates above to determine whether the average decision-maker (consumer) is willing to pay the extra **€300** to attain the high-end features \n",
    "\n",
    "In other words, we can use the WtP estimates to determine which model the smartphone maker can best bring to the market to maximise profits\n",
    "\n",
    "| Attribute | SMARTPHONE 1 (mainstream) | SMARTPHONE 2 (high-end) |\n",
    "| --- | :-: | :-: |\n",
    "| Size [inch]| 5.8 | 6.2 |\n",
    "| Storage [Gb]| 128 | 256 |\n",
    "| Camera quality | mid | high |\n",
    "| Price [€]| 400 | 700 |\n",
    "\n",
    "We compute the improvement to go from model 1 to model 2, per attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_improvement = 6.2 - 5.8 #inches\n",
    "storage_improvement = 256-128 #Gb\n",
    "camera_improvement = 3 - 2 # high - mid (unit quality level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compute the total WtP by multiplying the improvements with the WtPs per attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Willingness_to_pay_SM1_SM2 = WtP_size * size_improvement + WtP_storage * storage_improvement + WtP_camera * camera_improvement\n",
    "print('Willingness to pay for extra features of the high_end smartphone is €',\"{:.2f}\".format(Willingness_to_pay_SM1_SM2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3. So, which smartphone model can the company best bring to the market?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER**\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Exercise 2: My first Artificial Neural Network\n",
    "**Objectives:** \n",
    "* Understand how ANNs can be used for choice prediction\n",
    "* Learn that ANNs are likely to attain comparatively high model performance\n",
    "* Learn that using ANNs few behavioural inferences can be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. import Python packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Preprocess the data\n",
    "#### a. Identify features and outputs in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features\n",
    "X = df[['COST_1','SIZE_1','STORAGE_1','CAM_1','COST_2','SIZE_2','STORAGE_2','CAM_2','COST_3','SIZE_3','STORAGE_3','CAM_3','GENDER','INC']]\n",
    "\n",
    "# Define the output target\n",
    "Y = df['CHOICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Split the data in a training set and a test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Rescale the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "\n",
    "# Apply scaler to both the training and test set\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Define and ANN and train\n",
    "\n",
    "The structure of the ANN will be:\n",
    "\n",
    "- Input layer: All features of X dataframe. It's means all features of all alternatives and sociodemographic characteristics. \n",
    "- Hidden layer 1: A fully-connected (FC) layer of 5 nodes\n",
    "- Hidden layer 2: A fully-connected (FC) layer of 5 nodes\n",
    "- Output layer: A softmax (activation function) layer to assign probabilities ot each class (choices)\n",
    "\n",
    "In the next figure, you can see the ANN structure.\n",
    "\n",
    "<img src=\"https://github.com/cs4305tu/week6/blob/main/ANNstructure.png?raw=true\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ANN\n",
    "\n",
    "# Declare the number of layers and nodes per layer\n",
    "num_nodes = 5\n",
    "layers = (num_nodes,num_nodes) # Here we use a network with two hidden layers, with *num_nodes* each \n",
    "\n",
    "# Create the ANNs (MultiLayerPerceptron aka MLP)\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=layers, max_iter=1000) # We use the Adam optimiser, with a learning rate of 1e-5\n",
    "\n",
    "# Train the ANN. Note that sklearn does not permit anything else than batch gradient descent \n",
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Evaluate the performance of the trained ANN on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained ANN to make predictions for the test data\n",
    "probs_ANN_X_test = mlp.predict_proba(X_test)\n",
    "\n",
    "# Compute the prediction performance, based on the cross-entropy (aka log_loss). A lower cross-entropy signals a better model.\n",
    "cross_entropy_ANN = log_loss(Y_test, probs_ANN_X_test)\n",
    "print('The cross-entropy on the test data of the ANN is',\"{:.3f}\".format(cross_entropy_ANN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Compare the performance of ANN with the discrete choice models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do that, let's compute the cross-entropy of the RUM_MNL discrete choice model\n",
    "# Note that no distinction needs to be made between the (performance on) the test and train data\n",
    "\n",
    "# Get the estimated betas from the discrete choice model\n",
    "betas = results.getBetaValues()\n",
    "\n",
    "# Define compute objects\n",
    "prob_1 = models.logit(V, av, 1)\n",
    "prob_2 = models.logit(V, av, 2)\n",
    "prob_3 = models.logit(V, av, 3)\n",
    "\n",
    "# Define dictionary\n",
    "simulate_dict = {\n",
    "    'Prob_1': prob_1,\n",
    "    'Prob_2': prob_2,\n",
    "    'Prob_3': prob_3}\n",
    "\n",
    "# Create Biogeme object\n",
    "simulator = bio.BIOGEME(database, simulate_dict)\n",
    "\n",
    "# Compute probabilities using the estimated choice model\n",
    "probs_DCM = simulator.simulate(betas)\n",
    "\n",
    "# Compute the cross-entropy for the DCM\n",
    "cross_entropy_DCM = log_loss(df.CHOICE,probs_DCM)\n",
    "\n",
    "print('The cross-entropy of the DCM is        ',\"{:.3f}\".format(cross_entropy_DCM))\n",
    "print('The cross-entropy on the ANN is        ',\"{:.3f}\".format(cross_entropy_ANN))\n",
    "print('--> The improvement in cross-entropy is',\"{:.3f}\".format(cross_entropy_DCM - cross_entropy_ANN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1. To attain this performance improvement, the ANN uses considerably more weights. Compute by hand how many weights this network uses and verify your answer by inspecting the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also inspect the trained weights using the following syntax. Use this to verify your answer\n",
    "trained_weights_L1 = (mlp.coefs_[0]) # weights connecting input and 1st layer\n",
    "trained_weights_L2 = (mlp.coefs_[1]) # weights connecting 1st and 2nd layer\n",
    "trained_weights_L3 = (mlp.coefs_[2]) # weights connecting 2st and output layer\n",
    "\n",
    "trained_biases_L1 = (mlp.intercepts_[0]) # bias weights connecting input and 1st layer\n",
    "trained_biases_L2 = (mlp.intercepts_[1]) # bias weights connecting 1st and 2nd layer\n",
    "trained_biases_L3 = (mlp.intercepts_[2]) # bias weights connecting 2st and output layer\n",
    "no_weights = trained_weights_L1.size + trained_weights_L2.size + trained_weights_L3.size + trained_biases_L1.size + trained_biases_L2.size + trained_biases_L3.size\n",
    "# print('This network has', no_weights, 'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Behavioural inferences\n",
    "\n",
    "Unfortunately, we cannot make behavioural inferences based on the weights of the ANN. However, one simple way to still get a (partial) sense of what the ANN has learned is by simulating the effect of a (change in) attribute levels on the choice probabilities.\n",
    "\n",
    "To do so, we:\n",
    "\n",
    "1. Create an ndarray containing the following alternatives. Use Male (GENDER=0) and Income level 2 (INC=2)for the socio-demographic variables\n",
    "2. Apply the trained ANN to these data points. \n",
    "3. Plot the effect of the STORAGE of alternative 3 on the choice Probabilities and Utilties of alternatives 1,2, 3 for a Male with Income level 2.\n",
    "\n",
    "\n",
    "| COST_1 | SIZE_1 | STORAGE_1 | CAM_1 | COST_2 | SIZE_2 | STORAGE_2 | CAM_2 | COST_3 | SIZE_3 | STORAGE_3 | CAM_3 |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **32**  | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **64**  | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **128** | 2 |\n",
    "| 500 | 6.0 | 64 | 2 | 500 | 6.0 | 64 | 2 | 500 | 6.0 | **256** | 2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create an ndarray containing the alternatives in the table above\n",
    "X_sim = np.array([[500,6.0,64,2,500,6.0,64,2,500,6.0,32,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,64,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,128,2,0,2],[500,6.0,64,2,500,6.0,64,2,500,6.0,256,2,0,2]])\n",
    "\n",
    "# Step 2: Apply the trained ANN to these data points\n",
    "\n",
    "# Rescale input data using the same scaler as used for training\n",
    "X_sim_scaled = scaler.transform(X_sim) \n",
    "\n",
    "# Simulate the choice probabilities by applying the trained ANN\n",
    "probs_ANN_X_sim = mlp.predict_proba(X_sim_scaled)\n",
    "\n",
    "# Step 3: Plot the effect of the STORAGE of alternative 3 on the choice probabilities\n",
    "\n",
    "fig=plt.figure(figsize=(12,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(221)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,probs_ANN_X_sim[:,0], label= \"Probability alternative 1\")\n",
    "plt.plot(x_levels,probs_ANN_X_sim[:,1], label= \"Probability alternative 2\")\n",
    "plt.plot(x_levels,probs_ANN_X_sim[:,2], label= \"Probability alternative 3\")\n",
    "plt.title('ANN')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlim([0,260])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Step 3: Plot the effect of the STORAGE of alternative 3 on the utilities\n",
    "plt.subplot(223)\n",
    "utility_ANN_X_sim_V1 = 0 # As utilities are not absolute, we can arbitrarily fix V1 to zero\n",
    "utility_ANN_X_sim_V2 = np.log(probs_ANN_X_sim[:,1]/probs_ANN_X_sim[:,0]) # Utility of alternative 2 relative to V1\n",
    "utility_ANN_X_sim_V3 = np.log(probs_ANN_X_sim[:,2]/probs_ANN_X_sim[:,0]) # Utility of alternative 3 relative to V1\n",
    "plt.plot(x_levels,np.tile(utility_ANN_X_sim_V1,(len(x_levels))), label = \"Utility alternative 1\")\n",
    "plt.plot(x_levels,utility_ANN_X_sim_V2,                          label = \"Utility alternative 2\")\n",
    "plt.plot(x_levels,utility_ANN_X_sim_V3,                          label = \"Utility alternative 3\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('ANN')\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlim([0,260])\n",
    "\n",
    "# For comparison we also add the plots for the DCM\n",
    "# Compute utility using the estimated betas\n",
    "V1_X_sim = betas['B_cost']*X_sim[:,0] + betas['B_size']*X_sim[:,1] + betas['B_storage']*X_sim[:,2] + betas['B_camera']*X_sim[:,3]\n",
    "V2_X_sim = betas['B_cost']*X_sim[:,4] + betas['B_size']*X_sim[:,5] + betas['B_storage']*X_sim[:,6] + betas['B_camera']*X_sim[:,7]\n",
    "V3_X_sim = betas['B_cost']*X_sim[:,8] + betas['B_size']*X_sim[:,9] + betas['B_storage']*X_sim[:,10] + betas['B_camera']*X_sim[:,11]\n",
    "\n",
    "# Compute probabilities\n",
    "P1_sim = np.exp(V1_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P2_sim = np.exp(V2_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P3_sim = np.exp(V3_X_sim) / (np.exp(V1_X_sim)+np.exp(V2_X_sim)+np.exp(V3_X_sim))\n",
    "P_sim = np.transpose([P1_sim, P2_sim, P3_sim])\n",
    "\n",
    "plt.subplot(222)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,P_sim[:,0], label= \"Probability alternative 1\")\n",
    "plt.plot(x_levels,P_sim[:,1], label= \"Probability alternative 2\")\n",
    "plt.plot(x_levels,P_sim[:,2], label= \"Probability alternative 3\")\n",
    "plt.title('Discrete choice model')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlim([0,260])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.subplot(224)\n",
    "x_levels = np.array([32, 64, 128, 256])\n",
    "plt.plot(x_levels,V1_X_sim-V1_X_sim, label= \"Utility alternative 1\")\n",
    "plt.plot(x_levels,V2_X_sim-V1_X_sim, label= \"Utility alternative 2\")\n",
    "plt.plot(x_levels,V3_X_sim-V1_X_sim, label= \"Utility alternative 3\")\n",
    "plt.title('Discrete choice model')\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Storage space [Gb]\")\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlim([0,260])\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2. Has the ANN learned behaviourally meaningful/plausible relations?. In other words, look at what relations the ANN has learned and compare with what you would expect based on common sense and behavioural intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3: Re-run the code a couple of times to see how stable (robust) the results in the plots above are. Are they stable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 4: Based on the model estimation of Exercise 1 (Discrete choice model) and 2 (ANN). Any kind of variables missing in DCM compared to ANN when model is estimated? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER** <br>\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python3.9 (uyui)",
   "language": "python",
   "name": "uyui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
